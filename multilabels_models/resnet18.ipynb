{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import cv2\n","from tensorflow import keras\n","import os\n","from sklearn import model_selection\n","from sklearn import utils\n","from sklearn.metrics import confusion_matrix, roc_curve, RocCurveDisplay, roc_auc_score\n","from scipy import ndimage\n","from gc import collect\n","import matplotlib.pyplot as plt\n","from collections import Counter\n","from seaborn import heatmap\n"],"metadata":{"execution":{"iopub.status.busy":"2023-06-17T00:43:07.901122Z","iopub.execute_input":"2023-06-17T00:43:07.901596Z","iopub.status.idle":"2023-06-17T00:43:17.858008Z","shell.execute_reply.started":"2023-06-17T00:43:07.901557Z","shell.execute_reply":"2023-06-17T00:43:17.857073Z"},"trusted":true,"id":"1ecPYkoNrW0q","outputId":"ee7fe8f1-75db-4355-e4ee-7aaf64e75c6b"},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":["def get_labels(label_file):\n","    \"\"\"lê a tabela com as informações dos pacientes e retorna uma matriz com o ID e as labels\"\"\"\n","    labels = pd.read_csv(label_file)\n","    cancer_labels = dict()\n","\n","    for p in labels.index:\n","        cancer_labels[labels['PatientID'][p]] = [int(labels['Normal'][p]), int(labels['Actionable'][p]), int(labels['Benign'][p]), int(labels['Cancer'][p])]\n","\n","    return cancer_labels"],"metadata":{"execution":{"iopub.status.busy":"2023-06-17T00:44:03.325959Z","iopub.execute_input":"2023-06-17T00:44:03.326603Z","iopub.status.idle":"2023-06-17T00:44:03.333442Z","shell.execute_reply.started":"2023-06-17T00:44:03.326570Z","shell.execute_reply":"2023-06-17T00:44:03.332380Z"},"trusted":true,"id":"U_7O9c4YrW0t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels = get_labels('/kaggle/input/labelsssss/labels.csv')\n","numbers_per_class = [0, 0, 0, 0]\n","for i in labels:\n","    numbers_per_class[np.argmax(labels[i])] += 1\n","\n","proportion_per_class = [round(number_of_class/sum(numbers_per_class), 2) for number_of_class in numbers_per_class]\n","proportion_per_class"],"metadata":{"execution":{"iopub.status.busy":"2023-06-17T00:44:05.901304Z","iopub.execute_input":"2023-06-17T00:44:05.901983Z","iopub.status.idle":"2023-06-17T00:44:05.972333Z","shell.execute_reply.started":"2023-06-17T00:44:05.901951Z","shell.execute_reply":"2023-06-17T00:44:05.971327Z"},"trusted":true,"id":"sZOpyXJCrW0u","outputId":"4532ca9b-c0e9-4793-a0ab-d935baaa5914"},"execution_count":null,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"[0.35, 0.25, 0.23, 0.17]"},"metadata":{}}]},{"cell_type":"code","source":["path = '/kaggle/input/192x256xdepth/'\n","dirs = os.listdir(path)\n","\n","X = [path + i for i in os.listdir(path)]\n","y = [np.argmax(labels[(path+i)[-14:-4]]) for i in os.listdir(path)]"],"metadata":{"execution":{"iopub.status.busy":"2023-06-17T00:44:08.799103Z","iopub.execute_input":"2023-06-17T00:44:08.799466Z","iopub.status.idle":"2023-06-17T00:44:08.841047Z","shell.execute_reply.started":"2023-06-17T00:44:08.799417Z","shell.execute_reply":"2023-06-17T00:44:08.840121Z"},"trusted":true,"id":"w6PC-yJNrW0v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def balancing_batch(X, y, max_value):\n","    numbers_per_class = sorted(Counter(y).items())\n","\n","    if len(numbers_per_class) == 1:\n","        return X[0:1], y[0:1] #return only the first image because the batch has only one class\n","\n","    X, y = utils.shuffle(X, y)\n","    new_X, new_y = [], []\n","    counter_class_zero = 0\n","    counter_class_one = 0\n","    counter_class_two = 0\n","    counter_class_three = 0\n","\n","    max_per_class = int(max_value/4)\n","\n","    for test_x, test_y in zip(X, y):\n","        if test_y == 0 and counter_class_zero < max_per_class:\n","            new_X.append(test_x)\n","            new_y.append(test_y)\n","            counter_class_zero += 1\n","        elif test_y == 1 and counter_class_one < max_per_class:\n","            new_X.append(test_x)\n","            new_y.append(test_y)\n","            counter_class_one += 1\n","        elif test_y == 2 and counter_class_two < max_per_class:\n","            new_X.append(test_x)\n","            new_y.append(test_y)\n","            counter_class_two += 1\n","        elif test_y == 3 and counter_class_three < max_per_class:\n","            new_X.append(test_x)\n","            new_y.append(test_y)\n","            counter_class_three += 1\n","\n","    return np.array(new_X, dtype='float16'), np.array(new_y, dtype='uint8')"],"metadata":{"execution":{"iopub.status.busy":"2023-06-17T00:44:10.967417Z","iopub.execute_input":"2023-06-17T00:44:10.967818Z","iopub.status.idle":"2023-06-17T00:44:10.980522Z","shell.execute_reply.started":"2023-06-17T00:44:10.967790Z","shell.execute_reply":"2023-06-17T00:44:10.979542Z"},"trusted":true,"id":"KvRilRzErW0w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def separate_slices(img):\n","    'function to separate 2d images of 3d original image'\n","    slices = []\n","\n","    for i in range(img.shape[-2]):\n","        slices.append(np.array(img[:, :, i]))\n","\n","    slices.append(np.mean(img, axis=-2)) #including mean of slices\n","\n","    return slices"],"metadata":{"execution":{"iopub.status.busy":"2023-06-17T00:44:13.798891Z","iopub.execute_input":"2023-06-17T00:44:13.799316Z","iopub.status.idle":"2023-06-17T00:44:13.809771Z","shell.execute_reply.started":"2023-06-17T00:44:13.799280Z","shell.execute_reply":"2023-06-17T00:44:13.808786Z"},"trusted":true,"id":"6Bx9in_crW0w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, stratify=y,random_state=42, train_size=0.8)"],"metadata":{"execution":{"iopub.status.busy":"2023-06-17T00:44:16.190466Z","iopub.execute_input":"2023-06-17T00:44:16.190806Z","iopub.status.idle":"2023-06-17T00:44:16.200499Z","shell.execute_reply.started":"2023-06-17T00:44:16.190779Z","shell.execute_reply":"2023-06-17T00:44:16.199515Z"},"trusted":true,"id":"J3olKfI4rW0x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DataGenerator(tf.keras.utils.Sequence):\n","    'Generates data for Keras'\n","    def __init__(self, list_IDs, labels_dir, batch_size, sub_batch_size, dim_img, training, shuffle=True):\n","        self.list_IDs = list_IDs # array of strings with original images name with directory\n","        self.labels = self.__get_labels(labels_dir) #dict with labels of all images\n","        self.batch_size = batch_size #3d-images per batch\n","        self.sub_batch_size = sub_batch_size #quantity of sub-images per batch will be choose to train\n","        self.dim_img = dim_img # tuple with width and height of image like (192, 256)\n","        self.training = training # true if generator is for training, false if generator is for validation\n","        self.shuffle = shuffle # true or false to shuffle data after any epochs\n","        self.on_epoch_end() # call of the function\n","\n","\n","    def __get_labels(self, label_file):\n","        'take the dict with labels of images'\n","        labels = pd.read_csv(label_file)\n","        cancer_labels = dict()\n","\n","        for p in labels.index:\n","            cancer_labels[labels['PatientID'][p]] = [int(labels['Normal'][p]), int(labels['Actionable'][p]), int(labels['Benign'][p]), int(labels['Cancer'][p])]\n","\n","        return cancer_labels\n","\n","    def __data_augmentation(self, x):\n","        'generate variations of images'\n","        new_images = []\n","        x = x.astype('float16')\n","        new_images.append(x)\n","\n","        x = cv2.flip(x.astype('float32'), 1).astype('float16')\n","\n","        new_images.append(np.expand_dims(x, -1))\n","\n","        return utils.shuffle(new_images)\n","\n","    def __len__(self):\n","        'Denotes the number of batches per epoch'\n","        return int(np.floor(len(self.list_IDs) / self.batch_size))\n","\n","\n","    def __getitem__(self, index):\n","        'Generate one batch of data'\n","        # Generate indexes of the batch\n","        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","\n","        # Find list of IDs\n","        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n","\n","        # Generate data\n","        X, y = self.__data_generation(list_IDs_temp)\n","\n","        if self.training:\n","            X, y = balancing_batch(X, y, self.sub_batch_size)\n","            return np.array(X[0:self.sub_batch_size], dtype='float16'), np.array(y[0:self.sub_batch_size], dtype='uint8')\n","\n","        return np.array(X), np.array(y)\n","\n","    def on_epoch_end(self):\n","        'Updates indexes after each epoch'\n","        self.indexes = np.arange(len(self.list_IDs))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","\n","    def __data_generation(self, list_IDs_temp):\n","        'Generates data containing batch_size samples'\n","        X = []\n","        y = []\n","\n","        # Generate data\n","        for i, ID in enumerate(list_IDs_temp):\n","            # Store sample\n","            prev_len_X = len(X)\n","            full_image = np.load(ID)\n","            new_images = separate_slices(full_image)\n","            if self.training:\n","                for img in new_images:\n","                    X += self.__data_augmentation(img)\n","            else:\n","                X = np.array(new_images, dtype='float16')\n","\n","            #adding new data labels for y array\n","            for _ in range(len(X) - prev_len_X):\n","                y.append(self.labels[ID[-14:-4]]) #'-14:-4 represent a part of string with name of original image that slices was taken'\n","\n","        X, y = utils.shuffle(X, y)\n","        return X, y"],"metadata":{"execution":{"iopub.status.busy":"2023-06-17T00:44:18.393327Z","iopub.execute_input":"2023-06-17T00:44:18.393682Z","iopub.status.idle":"2023-06-17T00:44:18.414185Z","shell.execute_reply.started":"2023-06-17T00:44:18.393654Z","shell.execute_reply":"2023-06-17T00:44:18.413193Z"},"trusted":true,"id":"E83x_G8erW0y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ResidualUnit(keras.layers.Layer):\n","    def __init__(self, filters, strides=1, activation='relu', **kwargs):\n","        super().__init__(**kwargs)\n","        self.activation = keras.activations.get(activation)\n","        self.block_layers = [keras.layers.Conv2D(filters, kernel_size=(3,4), strides=strides, padding='same', use_bias=False),\n","                             keras.layers.BatchNormalization(),\n","                             self.activation,\n","                             keras.layers.Conv2D(filters, kernel_size=(3,4), strides=1, padding='same', use_bias=False),\n","                             keras.layers.BatchNormalization()]\n","\n","        self.skip_layers = []\n","        if strides > 1:\n","            self.skip_layers = [keras.layers.Conv2D(filters, kernel_size=(1,1), strides=strides, padding='same', use_bias=False),\n","                                keras.layers.BatchNormalization()]\n","\n","    def call(self, x):\n","        inputs = x\n","\n","        for layer in self.block_layers:\n","            x = layer(x)\n","\n","        for layer in self.skip_layers:\n","            inputs = layer(inputs)\n","\n","        return self.activation(x + inputs)\n","\n","def get_resnet18():\n","    resnet18 = keras.models.Sequential()\n","    resnet18.add(keras.layers.Conv2D(filters=64, kernel_size=(7,9), strides=2, padding='same', use_bias=False, input_shape=(192, 256, 1)))\n","    resnet18.add(keras.layers.BatchNormalization())\n","    resnet18.add(keras.layers.Activation(keras.activations.relu))\n","    resnet18.add(keras.layers.MaxPool2D(pool_size=(3,4), strides=2, padding='same'))\n","\n","    prev_filters = 64\n","    for filters in [64]*2 + [128]*2 + [256]*2 + [512]*2:\n","        if filters == prev_filters :\n","            strides = 1\n","        else:\n","            strides = 2\n","\n","        resnet18.add(ResidualUnit(filters, strides))\n","        prev_filters = filters\n","\n","    resnet18.add(keras.layers.GlobalAvgPool2D())\n","    resnet18.add(keras.layers.Flatten())\n","    resnet18.add(keras.layers.Dense(units=1, activation='sigmoid'))\n","\n","    return resnet18"],"metadata":{"execution":{"iopub.status.busy":"2023-06-17T00:44:27.769677Z","iopub.execute_input":"2023-06-17T00:44:27.770024Z","iopub.status.idle":"2023-06-17T00:44:27.785416Z","shell.execute_reply.started":"2023-06-17T00:44:27.769995Z","shell.execute_reply":"2023-06-17T00:44:27.784497Z"},"trusted":true,"id":"jcetlj7OrW00"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint_callback_auc1 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/cancer_auc1/',\n","                                                             save_weights_only=True,\n","                                                             monitor='val_AUC_1',\n","                                                             mode='max',\n","                                                             save_best_only=True)\n","checkpoint_callback_auc2 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/cancer_auc2/',\n","                                                             save_weights_only=True,\n","                                                             monitor='val_AUC_2',\n","                                                             mode='max',\n","                                                             save_best_only=True)\n","checkpoint_callback_auc3 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/cancer_auc3/',\n","                                                             save_weights_only=True,\n","                                                             monitor='val_AUC_3',\n","                                                             mode='max',\n","                                                             save_best_only=True)\n","checkpoint_callback_auc4 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/cancer_auc4/',\n","                                                             save_weights_only=True,\n","                                                             monitor='val_AUC_4',\n","                                                             mode='max',\n","                                                             save_best_only=True)\n","checkpoint_callback_auc5 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/cancer_auc5/',\n","                                                             save_weights_only=True,\n","                                                             monitor='val_AUC_5',\n","                                                             mode='max',\n","                                                             save_best_only=True)\n","\n","callbacks_list = [checkpoint_callback_auc1,\n","                  checkpoint_callback_auc2,\n","                  checkpoint_callback_auc3,\n","                  checkpoint_callback_auc4,\n","                  checkpoint_callback_auc5]\n","\n","def lr_scheduler(epoch, lr):\n","    return lr*0.9\n","\n","lr_decay_function = keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=0)"],"metadata":{"execution":{"iopub.status.busy":"2023-05-31T15:24:52.002761Z","iopub.execute_input":"2023-05-31T15:24:52.003104Z","iopub.status.idle":"2023-05-31T15:24:52.012926Z","shell.execute_reply.started":"2023-05-31T15:24:52.003077Z","shell.execute_reply":"2023-05-31T15:24:52.011703Z"},"trusted":true,"id":"BOoFqgfGrW1K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["histories = []\n","n_splits = 5\n","skf = model_selection.StratifiedShuffleSplit(n_splits=n_splits, random_state=314, train_size=0.85)\n","for number_of_split, data in enumerate(skf.split(X_train, y_train)):\n","    print(f'SPLIT {number_of_split+1}/{n_splits}:')\n","    train = [path + dirs[i] for i in data[0]]\n","    val = [path + dirs[j] for j in data[1]]\n","\n","    # Generators\n","    training_generator = DataGenerator(objective=[0, 0, 0, 1],\n","                                       list_IDs=train,\n","                                       labels_dir='/kaggle/input/labelsssss/labels.csv',\n","                                       dim_img=(192, 256),\n","                                       batch_size=5,\n","                                       sub_batch_size=400,\n","                                       shuffle=True,\n","                                       training=True)\n","\n","    validation_generator = DataGenerator(objective=[0, 0, 0, 1],\n","                                         list_IDs=val,\n","                                         labels_dir='/kaggle/input/labelsssss/labels.csv',\n","                                         dim_img=(192, 256),\n","                                         batch_size=1,\n","                                         sub_batch_size='IGNORED', #this argument will be ignored because training is false.\n","                                         shuffle=True,\n","                                         training=False)\n","\n","    resnet = get_resnet18()\n","\n","    resnet.compile(loss='binary_crossentropy',\n","                     optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n","                     metrics=[keras.metrics.AUC(name=f'AUC_{number_of_split+1}'),\n","                              keras.metrics.BinaryAccuracy(name='accuracy'),\n","                              keras.metrics.Precision(name='precision'),\n","                              keras.metrics.Recall(name='recall')])\n","\n","\n","    # Train model on dataset\n","    histories.append(resnet.fit(training_generator,\n","                                   validation_data=validation_generator,\n","                                   epochs=35,\n","                                   use_multiprocessing=True,\n","                                   workers=1,\n","                                   callbacks=[callbacks_list[number_of_split], lr_decay_function]))\n","    print('\\n')\n","    collect()"],"metadata":{"execution":{"iopub.status.busy":"2023-05-31T15:24:55.332270Z","iopub.execute_input":"2023-05-31T15:24:55.332892Z","iopub.status.idle":"2023-05-31T18:49:11.076108Z","shell.execute_reply.started":"2023-05-31T15:24:55.332862Z","shell.execute_reply":"2023-05-31T18:49:11.073649Z"},"trusted":true,"id":"SbH_mmxWrW1K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(25, 50))\n","plt.subplot(4, 2, 1)\n","for i, h in enumerate(histories):\n","    plt.plot(list(range(1, 36)), h.history['loss'], marker='o')\n","    plt.title('ResNET-18 Loss evolution - Training')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('Loss on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n","\n","plt.subplot(4, 2, 2)\n","for i, h in enumerate(histories):\n","    plt.plot(list(range(1, 36)), h.history['val_loss'], marker='o')\n","    plt.title('ResNET-18 Loss evolution - Validations')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('Loss on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n","\n","plt.subplot(4, 2, 3)\n","for i, h in enumerate(histories):\n","    plt.plot(list(range(1, 36)), h.history['accuracy'], marker='o')\n","    plt.title('ResNET-18 Accuracy evolution - Training')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('Accuracy on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n","\n","plt.subplot(4, 2, 4)\n","for i, h in enumerate(histories):\n","    plt.plot(list(range(1, 36)), h.history['val_accuracy'], marker='o')\n","    plt.title('ResNET-18 Accuracy evolution - Validations')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('Accuracy on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n","\n","plt.subplot(4, 2, 5)\n","for i, h in enumerate(histories):\n","    plt.plot(list(range(1, 36)), h.history['recall'], marker='o')\n","    plt.title('ResNET-18 Recall evolution - Training')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('Recall on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n","\n","plt.subplot(4, 2, 6)\n","for i, h in enumerate(histories):\n","    plt.plot(list(range(1, 36)), h.history['val_recall'], marker='o')\n","    plt.title('ResNET-18 Recall evolution - Validationss')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('Recall on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n","\n","plt.subplot(4, 2, 7)\n","for i, h in enumerate(histories):\n","    key_auc = f\"AUC_{i+1}\"\n","    plt.plot(list(range(1, 36)), h.history[key_auc], marker='o')\n","    plt.title('ResNET-18 AUC evolution - Training')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('AUC on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n","\n","plt.subplot(4, 2, 8)\n","for i, h in enumerate(histories):\n","    key_auc_val = f\"val_AUC_{i+1}\"\n","    plt.plot(list(range(1, 36)), h.history[key_auc_val], marker='o')\n","    plt.title('ResNET-18 AUC evolution - Validationss')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('AUC on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])"],"metadata":{"execution":{"iopub.status.busy":"2023-05-31T18:49:11.083915Z","iopub.execute_input":"2023-05-31T18:49:11.086235Z","iopub.status.idle":"2023-05-31T18:49:15.315933Z","shell.execute_reply.started":"2023-05-31T18:49:11.086184Z","shell.execute_reply":"2023-05-31T18:49:15.314948Z"},"trusted":true,"id":"FsMcJUfprW1L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Best results in validations for any k-fold: ')\n","for i, h in enumerate(histories):\n","    print(f'K-FOLD {i+1}:')\n","    print(\"TRAINING RESULTS:\")\n","    k = np.max(h.history[f'AUC_{i+1}'])\n","    print(f'Best AUC in train: {k}')\n","    k = np.max(h.history[f'accuracy'])\n","    print(f'Best Accuracy in train: {k}')\n","    k = np.max(h.history[f'precision'])\n","    print(f'Best Precision in train: {k}')\n","    k = np.max(h.history[f'recall'])\n","    print(f'Best Recall in train: {k}')\n","\n","    print(\"\\nVALIDATION RESULTS:\")\n","    k = np.max(h.history[f'val_AUC_{i+1}'])\n","    print(f'Best AUC in validation: {k}')\n","    k = np.max(h.history[f'val_accuracy'])\n","    print(f'Best Accuracy in validation: {k}')\n","    k = np.max(h.history[f'val_precision'])\n","    print(f'Best Precision in validation: {k}')\n","    k = np.max(h.history[f'val_recall'])\n","    print(f'Best Recall in validation: {k}')\n","    print()\n","    print(f'{50*\"=\"}')\n","    print()\n","\n","results = np.empty((4, 5))\n","for i, h in enumerate(histories):\n","    results[0][i] = np.max(h.history[f'val_AUC_{i+1}'])\n","    results[1][i] = np.max(h.history['val_accuracy'])\n","    results[2][i] = np.max(h.history['val_precision'])\n","    results[3][i] = np.max(h.history['val_recall'])\n","\n","print(f\"Average best AUC: {np.mean(results[0])}\")\n","print(f\"standard deviation AUC: {np.std(results[0])}\\n\")\n","print(f\"Average best Accuracy: {np.mean(results[1])}\")\n","print(f\"Standard Deviation Accuracy: {np.std(results[1])}\\n\")\n","print(f\"Average best Precision: {np.mean(results[2])}\")\n","print(f\"Standard Deviation Precision: {np.std(results[2])}\\n\")\n","print(f\"Average best Recall: {np.mean(results[3])}\")\n","print(f\"Standard Deviation Recall: {np.std(results[3])}\\n\")"],"metadata":{"execution":{"iopub.status.busy":"2023-05-31T18:49:15.317011Z","iopub.execute_input":"2023-05-31T18:49:15.317327Z","iopub.status.idle":"2023-05-31T18:49:15.348514Z","shell.execute_reply.started":"2023-05-31T18:49:15.317298Z","shell.execute_reply":"2023-05-31T18:49:15.347615Z"},"trusted":true,"id":"Tx2EpMc8rW1L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3dOVQSGkrW1M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**TESTS**"],"metadata":{"id":"bqv31muvrW1M"}},{"cell_type":"code","source":["training_generator = DataGenerator(objective=[0, 0, 0, 1],\n","                                       list_IDs=X_train,\n","                                       labels_dir='/kaggle/input/labelsssss/labels.csv',\n","                                       dim_img=(192, 256),\n","                                       batch_size=5,\n","                                       sub_batch_size=400,\n","                                       shuffle=True,\n","                                       training=True)\n","\n","resnet = get_resnet18()\n","\n","resnet.compile(loss='binary_crossentropy',\n","                  optimizer=keras.optimizers.Adam(8e-7),\n","                  metrics=[keras.metrics.AUC(name='AUC'),\n","                           keras.metrics.BinaryAccuracy(name='accuracy'),\n","                           keras.metrics.Precision(name='precision'),\n","                           keras.metrics.Recall(name='recall')])\n","\n","\n","# Train model on dataset\n","resnet.load_weights('/kaggle/working/models/cancer_auc4/') #start with best AUC in validations\n","history = resnet.fit(training_generator, epochs=10)"],"metadata":{"execution":{"iopub.status.busy":"2023-05-31T22:10:34.280905Z","iopub.execute_input":"2023-05-31T22:10:34.282072Z","iopub.status.idle":"2023-05-31T22:16:57.292678Z","shell.execute_reply.started":"2023-05-31T22:10:34.282014Z","shell.execute_reply":"2023-05-31T22:16:57.291646Z"},"trusted":true,"id":"-jz0lXw8rW1S","outputId":"cfa83cda-15a4-4cd4-f44b-eef499b7c8d4"},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/10\n35/35 [==============================] - 61s 1s/step - loss: 0.8559 - AUC: 0.6384 - accuracy: 0.5141 - precision: 0.5404 - recall: 0.1574\nEpoch 2/10\n35/35 [==============================] - 36s 1s/step - loss: 0.6765 - AUC: 0.8035 - accuracy: 0.7470 - precision: 0.8518 - recall: 0.5930\nEpoch 3/10\n35/35 [==============================] - 35s 1s/step - loss: 0.6318 - AUC: 0.8378 - accuracy: 0.7574 - precision: 0.8437 - recall: 0.6281\nEpoch 4/10\n35/35 [==============================] - 34s 988ms/step - loss: 0.7137 - AUC: 0.8077 - accuracy: 0.7632 - precision: 0.8169 - recall: 0.6744\nEpoch 5/10\n35/35 [==============================] - 35s 1s/step - loss: 0.7138 - AUC: 0.7687 - accuracy: 0.6870 - precision: 0.7628 - recall: 0.5377\nEpoch 6/10\n35/35 [==============================] - 35s 1s/step - loss: 0.3729 - AUC: 0.9409 - accuracy: 0.8795 - precision: 0.9326 - recall: 0.8163\nEpoch 7/10\n35/35 [==============================] - 34s 967ms/step - loss: 0.2469 - AUC: 0.9692 - accuracy: 0.8963 - precision: 0.9347 - recall: 0.8508\nEpoch 8/10\n35/35 [==============================] - 34s 967ms/step - loss: 0.4732 - AUC: 0.9084 - accuracy: 0.8404 - precision: 0.8721 - recall: 0.7958\nEpoch 9/10\n35/35 [==============================] - 35s 988ms/step - loss: 0.4435 - AUC: 0.8940 - accuracy: 0.8057 - precision: 0.8255 - recall: 0.7727\nEpoch 10/10\n35/35 [==============================] - 35s 991ms/step - loss: 0.1676 - AUC: 0.9853 - accuracy: 0.9398 - precision: 0.9379 - recall: 0.9412\n","output_type":"stream"}]},{"cell_type":"code","source":["res = []\n","for x in X_test:\n","    x = np.load(x)\n","    x = np.array(separate_slices(x))\n","    pred = resnet.predict(np.array(x), verbose=0)\n","    res.append(np.argmax(pred))\n","print(res)"],"metadata":{"execution":{"iopub.status.busy":"2023-05-31T22:17:06.705720Z","iopub.execute_input":"2023-05-31T22:17:06.706110Z","iopub.status.idle":"2023-05-31T22:17:39.861138Z","shell.execute_reply.started":"2023-05-31T22:17:06.706079Z","shell.execute_reply":"2023-05-31T22:17:39.860114Z"},"trusted":true,"id":"7obuo05WrW1S","outputId":"204e25e9-7792-418f-8a51-ac729fbfd143"},"execution_count":null,"outputs":[{"name":"stdout","text":"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","output_type":"stream"}]},{"cell_type":"code","source":["matrix_confusion = np.array([[0, 0, 0, 0],\n","                             [0, 0, 0, 0],\n","                             [0, 0, 0, 0],\n","                             [0, 0, 0, 0]])\n","\n","for y_pred, y_true in zip(res, y_test):\n","    matrix_confusion[y_pred][y_true] += 1\n","\n","print(matrix_confusion)"],"metadata":{"execution":{"iopub.status.busy":"2023-05-31T22:17:39.863149Z","iopub.execute_input":"2023-05-31T22:17:39.863453Z","iopub.status.idle":"2023-05-31T22:17:39.873668Z","shell.execute_reply.started":"2023-05-31T22:17:39.863427Z","shell.execute_reply":"2023-05-31T22:17:39.872537Z"},"trusted":true,"id":"F9I0_MIwrW1T","outputId":"2a49a06e-a3d3-4d38-9224-5ab4dee942b4"},"execution_count":null,"outputs":[{"name":"stdout","text":"[[39  6]\n [ 0  0]]\n0.8666666666666667\n","output_type":"stream"}]}]}