{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import cv2\n","from tensorflow import keras\n","import os\n","from sklearn import model_selection\n","from sklearn import utils\n","from sklearn.metrics import confusion_matrix, roc_curve, RocCurveDisplay, roc_auc_score\n","from scipy import ndimage\n","from gc import collect\n","import matplotlib.pyplot as plt\n","from collections import Counter\n","from seaborn import heatmap\n"],"metadata":{"execution":{"iopub.status.busy":"2023-06-11T16:04:21.651929Z","iopub.execute_input":"2023-06-11T16:04:21.652311Z","iopub.status.idle":"2023-06-11T16:04:30.093156Z","shell.execute_reply.started":"2023-06-11T16:04:21.652281Z","shell.execute_reply":"2023-06-11T16:04:30.092196Z"},"trusted":true,"id":"XvQUCUkWrX8l","outputId":"d3d2bdba-ffe0-42d3-9a52-52352666f3b8"},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":["def get_labels(label_file):\n","    \"\"\"lê a tabela com as informações dos pacientes e retorna uma matriz com o ID e as labels\"\"\"\n","    labels = pd.read_csv(label_file)\n","    cancer_labels = dict()\n","\n","    for p in labels.index:\n","        cancer_labels[labels['PatientID'][p]] = [int(labels['Normal'][p]), int(labels['Actionable'][p]), int(labels['Benign'][p]), int(labels['Cancer'][p])]\n","\n","    return cancer_labels"],"metadata":{"execution":{"iopub.status.busy":"2023-06-11T16:04:30.094830Z","iopub.execute_input":"2023-06-11T16:04:30.095706Z","iopub.status.idle":"2023-06-11T16:04:30.106210Z","shell.execute_reply.started":"2023-06-11T16:04:30.095678Z","shell.execute_reply":"2023-06-11T16:04:30.105269Z"},"trusted":true,"id":"2DlJN9UDrX8x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels = get_labels('/kaggle/input/labelsssss/labels.csv')\n","numbers_per_class = [0, 0, 0, 0]\n","for i in labels:\n","    numbers_per_class[np.argmax(labels[i])] += 1\n","\n","proportion_per_class = [round(number_of_class/sum(numbers_per_class), 2) for number_of_class in numbers_per_class]\n","proportion_per_class"],"metadata":{"execution":{"iopub.status.busy":"2023-06-11T16:04:30.107570Z","iopub.execute_input":"2023-06-11T16:04:30.107899Z","iopub.status.idle":"2023-06-11T16:04:30.190567Z","shell.execute_reply.started":"2023-06-11T16:04:30.107875Z","shell.execute_reply":"2023-06-11T16:04:30.189559Z"},"trusted":true,"id":"Zm6nVG4WrX8y","outputId":"41a42aa6-418e-47cd-b5ab-03b73d5692a8"},"execution_count":null,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"[0.35, 0.25, 0.23, 0.17]"},"metadata":{}}]},{"cell_type":"code","source":["path = '/kaggle/input/192x256xdepth/'\n","dirs = os.listdir(path)\n","\n","X = [path + i for i in os.listdir(path)]\n","y = [np.argmax(labels[(path+i)[-14:-4]]) for i in os.listdir(path)]"],"metadata":{"execution":{"iopub.status.busy":"2023-06-11T16:04:30.193006Z","iopub.execute_input":"2023-06-11T16:04:30.193366Z","iopub.status.idle":"2023-06-11T16:04:30.357579Z","shell.execute_reply.started":"2023-06-11T16:04:30.193335Z","shell.execute_reply":"2023-06-11T16:04:30.356643Z"},"trusted":true,"id":"NSF0loUyrX8z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def balancing_batch(X, y, max_value):\n","    numbers_per_class = sorted(Counter(y).items())\n","\n","    if len(numbers_per_class) == 1:\n","        return X[0:1], y[0:1] #return only the first image because the batch has only one class\n","\n","    X, y = utils.shuffle(X, y)\n","    new_X, new_y = [], []\n","    counter_class_zero = 0\n","    counter_class_one = 0\n","    counter_class_two = 0\n","    counter_class_three = 0\n","\n","    max_per_class = int(max_value/4)\n","\n","    for test_x, test_y in zip(X, y):\n","        if test_y == 0 and counter_class_zero < max_per_class:\n","            new_X.append(test_x)\n","            new_y.append(test_y)\n","            counter_class_zero += 1\n","        elif test_y == 1 and counter_class_one < max_per_class:\n","            new_X.append(test_x)\n","            new_y.append(test_y)\n","            counter_class_one += 1\n","        elif test_y == 2 and counter_class_two < max_per_class:\n","            new_X.append(test_x)\n","            new_y.append(test_y)\n","            counter_class_two += 1\n","        elif test_y == 3 and counter_class_three < max_per_class:\n","            new_X.append(test_x)\n","            new_y.append(test_y)\n","            counter_class_three += 1\n","\n","    return np.array(new_X, dtype='float16'), np.array(new_y, dtype='uint8')"],"metadata":{"execution":{"iopub.status.busy":"2023-06-11T16:04:30.359322Z","iopub.execute_input":"2023-06-11T16:04:30.359983Z","iopub.status.idle":"2023-06-11T16:04:30.369147Z","shell.execute_reply.started":"2023-06-11T16:04:30.359949Z","shell.execute_reply":"2023-06-11T16:04:30.368326Z"},"trusted":true,"id":"w8OqkVqWrX80"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def separate_slices(img):\n","    'function to separate 2d images of 3d original image'\n","    slices = []\n","\n","    for i in range(img.shape[-2]):\n","        slices.append(np.array(img[:, :, i]))\n","\n","    slices.append(np.mean(img, axis=-2)) #including mean of slices\n","\n","    return slices"],"metadata":{"execution":{"iopub.status.busy":"2023-06-11T16:04:31.347704Z","iopub.execute_input":"2023-06-11T16:04:31.348067Z","iopub.status.idle":"2023-06-11T16:04:31.354450Z","shell.execute_reply.started":"2023-06-11T16:04:31.348037Z","shell.execute_reply":"2023-06-11T16:04:31.353275Z"},"trusted":true,"id":"--mg1yqYrX80"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, stratify=y,random_state=42, train_size=0.8)"],"metadata":{"execution":{"iopub.status.busy":"2023-06-11T16:04:34.212998Z","iopub.execute_input":"2023-06-11T16:04:34.213450Z","iopub.status.idle":"2023-06-11T16:04:34.229382Z","shell.execute_reply.started":"2023-06-11T16:04:34.213413Z","shell.execute_reply":"2023-06-11T16:04:34.227944Z"},"trusted":true,"id":"6JhORbunrX81"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DataGenerator(tf.keras.utils.Sequence):\n","    'Generates data for Keras'\n","    def __init__(self, list_IDs, labels_dir, batch_size, sub_batch_size, dim_img, training, shuffle=True):\n","        self.list_IDs = list_IDs # array of strings with original images name with directory\n","        self.labels = self.__get_labels(labels_dir) #dict with labels of all images\n","        self.batch_size = batch_size #3d-images per batch\n","        self.sub_batch_size = sub_batch_size #quantity of sub-images per batch will be choose to train\n","        self.dim_img = dim_img # tuple with width and height of image like (192, 256)\n","        self.training = training # true if generator is for training, false if generator is for validation\n","        self.shuffle = shuffle # true or false to shuffle data after any epochs\n","        self.on_epoch_end() # call of the function\n","\n","\n","    def __get_labels(self, label_file):\n","        'take the dict with labels of images'\n","        labels = pd.read_csv(label_file)\n","        cancer_labels = dict()\n","\n","        for p in labels.index:\n","            cancer_labels[labels['PatientID'][p]] = [int(labels['Normal'][p]), int(labels['Actionable'][p]), int(labels['Benign'][p]), int(labels['Cancer'][p])]\n","\n","        return cancer_labels\n","\n","    def __data_augmentation(self, x):\n","        'generate variations of images'\n","        new_images = []\n","        x = x.astype('float16')\n","        new_images.append(x)\n","\n","        x = cv2.flip(x.astype('float32'), 1).astype('float16')\n","\n","        new_images.append(np.expand_dims(x, -1))\n","\n","        return utils.shuffle(new_images)\n","\n","    def __len__(self):\n","        'Denotes the number of batches per epoch'\n","        return int(np.floor(len(self.list_IDs) / self.batch_size))\n","\n","\n","    def __getitem__(self, index):\n","        'Generate one batch of data'\n","        # Generate indexes of the batch\n","        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","\n","        # Find list of IDs\n","        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n","\n","        # Generate data\n","        X, y = self.__data_generation(list_IDs_temp)\n","\n","        if self.training:\n","            X, y = balancing_batch(X, y, self.sub_batch_size)\n","            return np.array(X[0:self.sub_batch_size], dtype='float16'), np.array(y[0:self.sub_batch_size], dtype='uint8')\n","\n","        return np.array(X), np.array(y)\n","\n","    def on_epoch_end(self):\n","        'Updates indexes after each epoch'\n","        self.indexes = np.arange(len(self.list_IDs))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","\n","    def __data_generation(self, list_IDs_temp):\n","        'Generates data containing batch_size samples'\n","        X = []\n","        y = []\n","\n","        # Generate data\n","        for i, ID in enumerate(list_IDs_temp):\n","            # Store sample\n","            prev_len_X = len(X)\n","            full_image = np.load(ID)\n","            new_images = separate_slices(full_image)\n","            if self.training:\n","                for img in new_images:\n","                    X += self.__data_augmentation(img)\n","            else:\n","                X = np.array(new_images, dtype='float16')\n","\n","            #adding new data labels for y array\n","            for _ in range(len(X) - prev_len_X):\n","                y.append(self.labels[ID[-14:-4]]) #'-14:-4 represent a part of string with name of original image that slices was taken'\n","\n","        X, y = utils.shuffle(X, y)\n","        return X, y"],"metadata":{"execution":{"iopub.status.busy":"2023-06-11T16:04:36.183083Z","iopub.execute_input":"2023-06-11T16:04:36.184252Z","iopub.status.idle":"2023-06-11T16:04:36.206435Z","shell.execute_reply.started":"2023-06-11T16:04:36.184193Z","shell.execute_reply":"2023-06-11T16:04:36.205315Z"},"trusted":true,"id":"yNMdSEtsrX82"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ResidualUnit(keras.layers.Layer):\n","    def __init__(self, filters, strides=1, activation='relu', **kwargs):\n","        super().__init__(**kwargs)\n","        self.activation = keras.activations.get(activation)\n","        self.block_layers = [keras.layers.Conv2D(filters, kernel_size=(3,4), strides=strides, padding='same', use_bias=False),\n","                             keras.layers.BatchNormalization(),\n","                             self.activation,\n","                             keras.layers.Conv2D(filters, kernel_size=(3,4), strides=1, padding='same', use_bias=False),\n","                             keras.layers.BatchNormalization()]\n","\n","        self.skip_layers = []\n","        if strides > 1:\n","            self.skip_layers = [keras.layers.Conv2D(filters, kernel_size=(1,1), strides=strides, padding='same', use_bias=False),\n","                                keras.layers.BatchNormalization()]\n","\n","    def call(self, x):\n","        inputs = x\n","\n","        for layer in self.block_layers:\n","            x = layer(x)\n","\n","        for layer in self.skip_layers:\n","            inputs = layer(inputs)\n","\n","        return self.activation(x + inputs)\n","\n","def get_resnet34():\n","    resnet34 = keras.models.Sequential()\n","    resnet34.add(keras.layers.Conv2D(filters=64, kernel_size=(7,9), strides=2, padding='same', use_bias=False, input_shape=(192, 256, 1)))\n","    resnet34.add(keras.layers.BatchNormalization())\n","    resnet34.add(keras.layers.Activation(keras.activations.relu))\n","    resnet34.add(keras.layers.MaxPool2D(pool_size=(3,4), strides=2, padding='same'))\n","\n","    prev_filters = 64\n","    for filters in [64]*3 + [128]*4 + [256]*6 + [512]*3:\n","        if filters == prev_filters :\n","            strides = 1\n","        else:\n","            strides = 2\n","\n","        resnet34.add(ResidualUnit(filters, strides))\n","        prev_filters = filters\n","\n","    resnet34.add(keras.layers.GlobalAvgPool2D())\n","    resnet34.add(keras.layers.Flatten())\n","    resnet34.add(keras.layers.Dense(units=1, activation='sigmoid'))\n","\n","    return resnet34"],"metadata":{"execution":{"iopub.status.busy":"2023-06-11T16:04:42.173612Z","iopub.execute_input":"2023-06-11T16:04:42.173976Z","iopub.status.idle":"2023-06-11T16:04:42.188328Z","shell.execute_reply.started":"2023-06-11T16:04:42.173945Z","shell.execute_reply":"2023-06-11T16:04:42.187174Z"},"trusted":true,"id":"YNfKvWhorX83"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint_callback_auc1 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/cancer_auc1/',\n","                                                             save_weights_only=True,\n","                                                             monitor='val_AUC_1',\n","                                                             mode='max',\n","                                                             save_best_only=True)\n","checkpoint_callback_auc2 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/cancer_auc2/',\n","                                                             save_weights_only=True,\n","                                                             monitor='val_AUC_2',\n","                                                             mode='max',\n","                                                             save_best_only=True)\n","checkpoint_callback_auc3 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/cancer_auc3/',\n","                                                             save_weights_only=True,\n","                                                             monitor='val_AUC_3',\n","                                                             mode='max',\n","                                                             save_best_only=True)\n","checkpoint_callback_auc4 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/cancer_auc4/',\n","                                                             save_weights_only=True,\n","                                                             monitor='val_AUC_4',\n","                                                             mode='max',\n","                                                             save_best_only=True)\n","checkpoint_callback_auc5 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/cancer_auc5/',\n","                                                             save_weights_only=True,\n","                                                             monitor='val_AUC_5',\n","                                                             mode='max',\n","                                                             save_best_only=True)\n","\n","callbacks_list = [checkpoint_callback_auc1,\n","                  checkpoint_callback_auc2,\n","                  checkpoint_callback_auc3,\n","                  checkpoint_callback_auc4,\n","                  checkpoint_callback_auc5]\n","\n","def lr_scheduler(epoch, lr):\n","    return lr*0.9\n","\n","lr_decay_function = keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=0)"],"metadata":{"execution":{"iopub.status.busy":"2023-06-11T09:45:55.931471Z","iopub.execute_input":"2023-06-11T09:45:55.931851Z","iopub.status.idle":"2023-06-11T09:45:55.943511Z","shell.execute_reply.started":"2023-06-11T09:45:55.931816Z","shell.execute_reply":"2023-06-11T09:45:55.942681Z"},"trusted":true,"id":"xQlvmcLrrX9H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["histories = []\n","n_splits = 5\n","skf = model_selection.StratifiedShuffleSplit(n_splits=n_splits, random_state=314, train_size=0.85)\n","for number_of_split, data in enumerate(skf.split(X_train, y_train)):\n","    print(f'SPLIT {number_of_split+1}/{n_splits}:')\n","    train = [path + dirs[i] for i in data[0]]\n","    val = [path + dirs[j] for j in data[1]]\n","\n","    # Generators\n","    training_generator = DataGenerator(list_IDs=train,\n","                                       labels_dir='/kaggle/input/labelsssss/labels.csv',\n","                                       dim_img=(192, 256),\n","                                       batch_size=5,\n","                                       sub_batch_size=400,\n","                                       shuffle=True,\n","                                       training=True)\n","\n","    validation_generator = DataGenerator(list_IDs=val,\n","                                         labels_dir='/kaggle/input/labelsssss/labels.csv',\n","                                         dim_img=(192, 256),\n","                                         batch_size=1,\n","                                         sub_batch_size='IGNORED', #this argument will be ignored because training is false.\n","                                         shuffle=True,\n","                                         training=False)\n","\n","    resnet = get_resnet34()\n","\n","    resnet.compile(loss='binary_crossentropy',\n","                     optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n","                     metrics=[keras.metrics.AUC(name=f'AUC_{number_of_split+1}'),\n","                              keras.metrics.BinaryAccuracy(name='accuracy'),\n","                              keras.metrics.Precision(name='precision'),\n","                              keras.metrics.Recall(name='recall')])\n","\n","\n","    # Train model on dataset\n","    histories.append(resnet.fit(training_generator,\n","                                   validation_data=validation_generator,\n","                                   epochs=35,\n","                                   use_multiprocessing=True,\n","                                   workers=1,\n","                                   callbacks=[callbacks_list[number_of_split], lr_decay_function]))\n","    print('\\n')\n","    collect()"],"metadata":{"execution":{"iopub.status.busy":"2023-06-11T09:45:55.945606Z","iopub.execute_input":"2023-06-11T09:45:55.946429Z","iopub.status.idle":"2023-06-11T13:13:17.191963Z","shell.execute_reply.started":"2023-06-11T09:45:55.946395Z","shell.execute_reply":"2023-06-11T13:13:17.190148Z"},"trusted":true,"id":"jTPuKAFTrX9I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(25, 50))\n","plt.subplot(4, 2, 1)\n","for i, h in enumerate(histories):\n","    plt.plot(list(range(1, 36)), h.history['loss'], marker='o')\n","    plt.title('ResNET-34 Loss evolution - Training')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('Loss on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n","\n","plt.subplot(4, 2, 2)\n","for i, h in enumerate(histories):\n","    plt.plot(list(range(1, 36)), h.history['val_loss'], marker='o')\n","    plt.title('ResNET-34 Loss evolution - Validations')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('Loss on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n","\n","plt.subplot(4, 2, 3)\n","for i, h in enumerate(histories):\n","    plt.plot(list(range(1, 36)), h.history['accuracy'], marker='o')\n","    plt.title('ResNET-34 Accuracy evolution - Training')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('Accuracy on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n","\n","plt.subplot(4, 2, 4)\n","for i, h in enumerate(histories):\n","    plt.plot(list(range(1, 36)), h.history['val_accuracy'], marker='o')\n","    plt.title('ResNET-34 Accuracy evolution - Validations')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('Accuracy on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n","\n","plt.subplot(4, 2, 5)\n","for i, h in enumerate(histories):\n","    plt.plot(list(range(1, 36)), h.history['recall'], marker='o')\n","    plt.title('ResNET-34 Recall evolution - Training')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('Recall on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n","\n","plt.subplot(4, 2, 6)\n","for i, h in enumerate(histories):\n","    plt.plot(list(range(1, 36)), h.history['val_recall'], marker='o')\n","    plt.title('ResNET-34 Recall evolution - Validations')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('Recall on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n","\n","plt.subplot(4, 2, 7)\n","for i, h in enumerate(histories):\n","    key_auc = f\"AUC_{i+1}\"\n","    plt.plot(list(range(1, 36)), h.history[key_auc], marker='o')\n","    plt.title('ResNET-34 AUC evolution - Training')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('AUC on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n","\n","plt.subplot(4, 2, 8)\n","for i, h in enumerate(histories):\n","    key_auc_val = f\"val_AUC_{i+1}\"\n","    plt.plot(list(range(1, 36)), h.history[key_auc_val], marker='o')\n","    plt.title('ResNET-34 AUC evolution - Validations')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('AUC on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])"],"metadata":{"execution":{"iopub.status.busy":"2023-06-11T13:13:17.198127Z","iopub.execute_input":"2023-06-11T13:13:17.198453Z","iopub.status.idle":"2023-06-11T13:13:20.571964Z","shell.execute_reply.started":"2023-06-11T13:13:17.198424Z","shell.execute_reply":"2023-06-11T13:13:20.571057Z"},"trusted":true,"id":"u-0kxOLNrX9I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Best results in validations for any k-fold: ')\n","for i, h in enumerate(histories):\n","    print(f'K-FOLD {i+1}:')\n","    print(\"TRAINING RESULTS:\")\n","    k = np.max(h.history[f'AUC_{i+1}'])\n","    print(f'Best AUC in train: {k}')\n","    k = np.max(h.history[f'accuracy'])\n","    print(f'Best Accuracy in train: {k}')\n","    k = np.max(h.history[f'precision'])\n","    print(f'Best Precision in train: {k}')\n","    k = np.max(h.history[f'recall'])\n","    print(f'Best Recall in train: {k}')\n","\n","    print(\"\\nVALIDATION RESULTS:\")\n","    k = np.max(h.history[f'val_AUC_{i+1}'])\n","    print(f'Best AUC in validation: {k}')\n","    k = np.max(h.history[f'val_accuracy'])\n","    print(f'Best Accuracy in validation: {k}')\n","    k = np.max(h.history[f'val_precision'])\n","    print(f'Best Precision in validation: {k}')\n","    k = np.max(h.history[f'val_recall'])\n","    print(f'Best Recall in validation: {k}')\n","    print()\n","    print(f'{50*\"=\"}')\n","    print()\n","\n","results = np.empty((4, 5))\n","for i, h in enumerate(histories):\n","    results[0][i] = np.max(h.history[f'val_AUC_{i+1}'])\n","    results[1][i] = np.max(h.history['val_accuracy'])\n","    results[2][i] = np.max(h.history['val_precision'])\n","    results[3][i] = np.max(h.history['val_recall'])\n","\n","print(f\"Average best AUC: {np.mean(results[0])}\")\n","print(f\"standard deviation AUC: {np.std(results[0])}\\n\")\n","print(f\"Average best Accuracy: {np.mean(results[1])}\")\n","print(f\"Standard Deviation Accuracy: {np.std(results[1])}\\n\")\n","print(f\"Average best Precision: {np.mean(results[2])}\")\n","print(f\"Standard Deviation Precision: {np.std(results[2])}\\n\")\n","print(f\"Average best Recall: {np.mean(results[3])}\")\n","print(f\"Standard Deviation Recall: {np.std(results[3])}\\n\")"],"metadata":{"execution":{"iopub.status.busy":"2023-06-11T13:13:20.573351Z","iopub.execute_input":"2023-06-11T13:13:20.575164Z","iopub.status.idle":"2023-06-11T13:13:20.593880Z","shell.execute_reply.started":"2023-06-11T13:13:20.575128Z","shell.execute_reply":"2023-06-11T13:13:20.592790Z"},"trusted":true,"id":"ARfJhqeErX9J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**TESTS**"],"metadata":{"id":"7w-3l7xjrX9K"}},{"cell_type":"code","source":["training_generator = DataGenerator(objective=[0, 0, 0, 1],\n","                                       list_IDs=X_train,\n","                                       labels_dir='/kaggle/input/labelsssss/labels.csv',\n","                                       dim_img=(192, 256),\n","                                       batch_size=5,\n","                                       sub_batch_size=400,\n","                                       shuffle=True,\n","                                       training=True)\n","\n","resnet = get_resnet34()\n","\n","resnet.compile(loss='binary_crossentropy',\n","                  optimizer=keras.optimizers.Adam(1e-7),\n","                  metrics=[keras.metrics.AUC(name='AUC'),\n","                           keras.metrics.BinaryAccuracy(name='accuracy'),\n","                           keras.metrics.Precision(name='precision'),\n","                           keras.metrics.Recall(name='recall')])\n","\n","\n","# Train model on dataset\n","resnet.load_weights('/kaggle/working/models/cancer_auc3/') #start with best AUC in validations\n","history = resnet.fit(training_generator, epochs=10)"],"metadata":{"execution":{"iopub.status.busy":"2023-06-11T16:51:51.106510Z","iopub.execute_input":"2023-06-11T16:51:51.106916Z","iopub.status.idle":"2023-06-11T16:58:30.468336Z","shell.execute_reply.started":"2023-06-11T16:51:51.106886Z","shell.execute_reply":"2023-06-11T16:58:30.467390Z"},"trusted":true,"id":"bs43Jse-rX9h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["res = []\n","for x in X_test:\n","    x = np.load(x)\n","    x = np.array(separate_slices(x))\n","    pred = resnet.predict(np.array(x), verbose=0)\n","    res.append(np.argmax(pred))\n","print(res)"],"metadata":{"execution":{"iopub.status.busy":"2023-06-11T16:58:30.470409Z","iopub.execute_input":"2023-06-11T16:58:30.470849Z","iopub.status.idle":"2023-06-11T16:59:19.733970Z","shell.execute_reply.started":"2023-06-11T16:58:30.470815Z","shell.execute_reply":"2023-06-11T16:59:19.732947Z"},"trusted":true,"id":"aYbZO8hBrX9h","outputId":"5c5b9179-9c72-481d-ea18-83f470776fee"},"execution_count":null,"outputs":[{"name":"stdout","text":"[0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1]\n","output_type":"stream"}]},{"cell_type":"code","source":["matrix_confusion = np.array([[0, 0, 0, 0],\n","                             [0, 0, 0, 0],\n","                             [0, 0, 0, 0],\n","                             [0, 0, 0, 0]])\n","\n","for y_pred, y_true in zip(res, y_test):\n","    matrix_confusion[y_pred][y_true] += 1\n","\n","print(matrix_confusion)"],"metadata":{"execution":{"iopub.status.busy":"2023-06-11T16:59:19.735296Z","iopub.execute_input":"2023-06-11T16:59:19.736287Z","iopub.status.idle":"2023-06-11T16:59:19.744078Z","shell.execute_reply.started":"2023-06-11T16:59:19.736243Z","shell.execute_reply":"2023-06-11T16:59:19.743055Z"},"trusted":true,"id":"Tt71zHDIrX9i","outputId":"cb7cc9fb-88e1-4b52-8a1e-2fd1337e7a3d"},"execution_count":null,"outputs":[{"name":"stdout","text":"[[30  4]\n [ 9  2]]\n0.7111111111111111\n","output_type":"stream"}]}]}