{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import cv2\n","from tensorflow import keras\n","import os\n","from sklearn import model_selection\n","from sklearn import utils\n","from sklearn.metrics import confusion_matrix, roc_curve, RocCurveDisplay, roc_auc_score\n","from scipy import ndimage\n","from gc import collect\n","import matplotlib.pyplot as plt\n","from collections import Counter\n","from seaborn import heatmap\n"],"metadata":{"execution":{"iopub.status.busy":"2023-06-10T20:36:55.737576Z","iopub.execute_input":"2023-06-10T20:36:55.738436Z","iopub.status.idle":"2023-06-10T20:37:05.452607Z","shell.execute_reply.started":"2023-06-10T20:36:55.738401Z","shell.execute_reply":"2023-06-10T20:37:05.451669Z"},"trusted":true,"id":"T_S6n5vsrWYh","outputId":"d3436fad-ec34-49dc-b125-987ad9577ca4"},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":["def get_labels(label_file):\n","    \"\"\"lê a tabela com as informações dos pacientes e retorna uma matriz com o ID e as labels\"\"\"\n","    labels = pd.read_csv(label_file)\n","    cancer_labels = dict()\n","\n","    for p in labels.index:\n","        cancer_labels[labels['PatientID'][p]] = [int(labels['Normal'][p]), int(labels['Actionable'][p]), int(labels['Benign'][p]), int(labels['Cancer'][p])]\n","\n","    return cancer_labels"],"metadata":{"execution":{"iopub.status.busy":"2023-06-10T20:37:05.454347Z","iopub.execute_input":"2023-06-10T20:37:05.455101Z","iopub.status.idle":"2023-06-10T20:37:05.461454Z","shell.execute_reply.started":"2023-06-10T20:37:05.455055Z","shell.execute_reply":"2023-06-10T20:37:05.460522Z"},"trusted":true,"id":"tVI3k88ArWYj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels = get_labels('/kaggle/input/labelsssss/labels.csv')\n","numbers_per_class = [0, 0, 0, 0]\n","for i in labels:\n","    numbers_per_class[np.argmax(labels[i])] += 1\n","\n","proportion_per_class = [round(number_of_class/sum(numbers_per_class), 2) for number_of_class in numbers_per_class]\n","proportion_per_class"],"metadata":{"execution":{"iopub.status.busy":"2023-06-10T20:37:05.462607Z","iopub.execute_input":"2023-06-10T20:37:05.463544Z","iopub.status.idle":"2023-06-10T20:37:05.533415Z","shell.execute_reply.started":"2023-06-10T20:37:05.463510Z","shell.execute_reply":"2023-06-10T20:37:05.532404Z"},"trusted":true,"id":"xMchkNygrWYk","outputId":"c5ff7478-26b7-4bb1-cd2c-241d9bde7f5f"},"execution_count":null,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"[0.35, 0.25, 0.23, 0.17]"},"metadata":{}}]},{"cell_type":"code","source":["path = '/kaggle/input/192x256xdepth/'\n","dirs = os.listdir(path)\n","\n","X = [path + i for i in os.listdir(path)]\n","y = [np.argmax(labels[(path+i)[-14:-4]]) for i in os.listdir(path)]"],"metadata":{"execution":{"iopub.status.busy":"2023-06-10T20:52:31.836266Z","iopub.execute_input":"2023-06-10T20:52:31.836681Z","iopub.status.idle":"2023-06-10T20:52:31.947011Z","shell.execute_reply.started":"2023-06-10T20:52:31.836650Z","shell.execute_reply":"2023-06-10T20:52:31.946151Z"},"trusted":true,"id":"f6QN19dMrWYl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def balancing_batch(X, y, max_value):\n","    numbers_per_class = sorted(Counter(y).items())\n","\n","    if len(numbers_per_class) == 1:\n","        return X[0:1], y[0:1] #return only the first image because the batch has only one class\n","\n","    X, y = utils.shuffle(X, y)\n","    new_X, new_y = [], []\n","    counter_class_zero = 0\n","    counter_class_one = 0\n","    counter_class_two = 0\n","    counter_class_three = 0\n","\n","    max_per_class = int(max_value/4)\n","\n","    for test_x, test_y in zip(X, y):\n","        if test_y == 0 and counter_class_zero < max_per_class:\n","            new_X.append(test_x)\n","            new_y.append(test_y)\n","            counter_class_zero += 1\n","        elif test_y == 1 and counter_class_one < max_per_class:\n","            new_X.append(test_x)\n","            new_y.append(test_y)\n","            counter_class_one += 1\n","        elif test_y == 2 and counter_class_two < max_per_class:\n","            new_X.append(test_x)\n","            new_y.append(test_y)\n","            counter_class_two += 1\n","        elif test_y == 3 and counter_class_three < max_per_class:\n","            new_X.append(test_x)\n","            new_y.append(test_y)\n","            counter_class_three += 1\n","\n","    return np.array(new_X, dtype='float16'), np.array(new_y, dtype='uint8')"],"metadata":{"execution":{"iopub.status.busy":"2023-06-10T20:52:34.562500Z","iopub.execute_input":"2023-06-10T20:52:34.562848Z","iopub.status.idle":"2023-06-10T20:52:34.573201Z","shell.execute_reply.started":"2023-06-10T20:52:34.562818Z","shell.execute_reply":"2023-06-10T20:52:34.572175Z"},"trusted":true,"id":"SLKvxdFhrWYl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def separate_slices(img):\n","    'function to separate 2d images of 3d original image'\n","    slices = []\n","\n","    for i in range(img.shape[-2]):\n","        slices.append(np.array(img[:, :, i]))\n","\n","    slices.append(np.mean(img, axis=-2)) #including mean of slices\n","\n","    return slices"],"metadata":{"execution":{"iopub.status.busy":"2023-06-10T20:52:37.642981Z","iopub.execute_input":"2023-06-10T20:52:37.643665Z","iopub.status.idle":"2023-06-10T20:52:37.649905Z","shell.execute_reply.started":"2023-06-10T20:52:37.643633Z","shell.execute_reply":"2023-06-10T20:52:37.648850Z"},"trusted":true,"id":"HQdNGaWfrWYm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, stratify=y,random_state=42, train_size=0.8)"],"metadata":{"execution":{"iopub.status.busy":"2023-06-10T20:52:41.092350Z","iopub.execute_input":"2023-06-10T20:52:41.092774Z","iopub.status.idle":"2023-06-10T20:52:41.108174Z","shell.execute_reply.started":"2023-06-10T20:52:41.092738Z","shell.execute_reply":"2023-06-10T20:52:41.106961Z"},"trusted":true,"id":"5JBWh1WOrWYm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DataGenerator(tf.keras.utils.Sequence):\n","    'Generates data for Keras'\n","    def __init__(self, list_IDs, labels_dir, batch_size, sub_batch_size, dim_img, training, shuffle=True):\n","        self.list_IDs = list_IDs # array of strings with original images name with directory\n","        self.labels = self.__get_labels(labels_dir) #dict with labels of all images\n","        self.batch_size = batch_size #3d-images per batch\n","        self.sub_batch_size = sub_batch_size #quantity of sub-images per batch will be choose to train\n","        self.dim_img = dim_img # tuple with width and height of image like (192, 256)\n","        self.training = training # true if generator is for training, false if generator is for validation\n","        self.shuffle = shuffle # true or false to shuffle data after any epochs\n","        self.on_epoch_end() # call of the function\n","\n","\n","    def __get_labels(self, label_file):\n","        'take the dict with labels of images'\n","        labels = pd.read_csv(label_file)\n","        cancer_labels = dict()\n","\n","        for p in labels.index:\n","            cancer_labels[labels['PatientID'][p]] = [int(labels['Normal'][p]), int(labels['Actionable'][p]), int(labels['Benign'][p]), int(labels['Cancer'][p])]\n","\n","        return cancer_labels\n","\n","    def __data_augmentation(self, x):\n","        'generate variations of images'\n","        new_images = []\n","        x = x.astype('float16')\n","        new_images.append(x)\n","\n","        x = cv2.flip(x.astype('float32'), 1).astype('float16')\n","\n","        new_images.append(np.expand_dims(x, -1))\n","\n","        return utils.shuffle(new_images)\n","\n","    def __len__(self):\n","        'Denotes the number of batches per epoch'\n","        return int(np.floor(len(self.list_IDs) / self.batch_size))\n","\n","\n","    def __getitem__(self, index):\n","        'Generate one batch of data'\n","        # Generate indexes of the batch\n","        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","\n","        # Find list of IDs\n","        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n","\n","        # Generate data\n","        X, y = self.__data_generation(list_IDs_temp)\n","\n","        if self.training:\n","            X, y = balancing_batch(X, y, self.sub_batch_size)\n","            return np.array(X[0:self.sub_batch_size], dtype='float16'), np.array(y[0:self.sub_batch_size], dtype='uint8')\n","\n","        return np.array(X), np.array(y)\n","\n","    def on_epoch_end(self):\n","        'Updates indexes after each epoch'\n","        self.indexes = np.arange(len(self.list_IDs))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","\n","    def __data_generation(self, list_IDs_temp):\n","        'Generates data containing batch_size samples'\n","        X = []\n","        y = []\n","\n","        # Generate data\n","        for i, ID in enumerate(list_IDs_temp):\n","            # Store sample\n","            prev_len_X = len(X)\n","            full_image = np.load(ID)\n","            new_images = separate_slices(full_image)\n","            if self.training:\n","                for img in new_images:\n","                    X += self.__data_augmentation(img)\n","            else:\n","                X = np.array(new_images, dtype='float16')\n","\n","            #adding new data labels for y array\n","            for _ in range(len(X) - prev_len_X):\n","                y.append(self.labels[ID[-14:-4]]) #'-14:-4 represent a part of string with name of original image that slices was taken'\n","\n","        X, y = utils.shuffle(X, y)\n","        return X, y"],"metadata":{"execution":{"iopub.status.busy":"2023-06-10T20:52:42.772998Z","iopub.execute_input":"2023-06-10T20:52:42.773338Z","iopub.status.idle":"2023-06-10T20:52:42.792367Z","shell.execute_reply.started":"2023-06-10T20:52:42.773310Z","shell.execute_reply":"2023-06-10T20:52:42.791251Z"},"trusted":true,"id":"9y4N4KN0rWYm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SE_ResidualUnit(keras.layers.Layer):\n","    def __init__(self, filters, strides=1, activation='relu', **kwargs):\n","        super().__init__(**kwargs)\n","        self.activation = keras.activations.get(activation)\n","\n","        self.SE = [keras.layers.GlobalAvgPool2D(),\n","                   keras.layers.Flatten(),\n","                   keras.layers.Dense(filters//4, activation='relu'),\n","                   keras.layers.Dense(filters, activation='sigmoid'),\n","                   keras.layers.Reshape([1,1,filters])]\n","\n","        self.block_layers = [keras.layers.Conv2D(filters//4, kernel_size=(1,1), strides=1, padding='same', use_bias=False),\n","                             keras.layers.BatchNormalization(),\n","                             self.activation,\n","                             keras.layers.Conv2D(filters//4, kernel_size=(3,4), strides=strides, padding='same', use_bias=False),\n","                             keras.layers.BatchNormalization(),\n","                             self.activation,\n","                             keras.layers.Conv2D(filters, kernel_size=(1,1), strides=1, padding='same', use_bias=False),\n","                             keras.layers.BatchNormalization()]\n","\n","        self.skip_layers = []\n","        if strides > 1:\n","            self.skip_layers = [keras.layers.Conv2D(filters, kernel_size=(1,1), strides=strides, padding='same', use_bias=False),\n","                                keras.layers.BatchNormalization()]\n","\n","    def call(self, x):\n","        inputs = tf.identity(x)\n","        x1 = tf.identity(x)\n","\n","        for layer in self.block_layers:\n","            x1 = layer(x1)\n","\n","        x2 = tf.identity(x1)\n","        for layer in self.SE:\n","            x2 = layer(x2)\n","\n","        prod_calibration = x1*x2\n","\n","        for layer in self.skip_layers:\n","            inputs = layer(inputs)\n","\n","\n","        return tf.concat([prod_calibration, inputs], axis=-1)\n","\n","def get_resnet18():\n","    resnet18 = keras.models.Sequential()\n","    resnet18.add(keras.layers.Conv2D(filters=64, kernel_size=(7,9), strides=2, padding='same', use_bias=False, input_shape=(192, 256, 1)))\n","    resnet18.add(keras.layers.BatchNormalization())\n","    resnet18.add(keras.layers.Activation(keras.activations.relu))\n","    resnet18.add(keras.layers.MaxPool2D(pool_size=(3,4), strides=2, padding='same'))\n","\n","    prev_filters = 64\n","    for filters in [64]*2 + [128]*2 + [256]*2 + [512]*2:\n","        if filters == prev_filters :\n","            strides = 1\n","        else:\n","            strides = 2\n","        resnet18.add(SE_ResidualUnit(filters, strides))\n","        prev_filters = filters\n","\n","    resnet18.add(keras.layers.GlobalAvgPool2D())\n","    resnet18.add(keras.layers.Flatten())\n","    resnet18.add(keras.layers.Dense(units=1, activation='sigmoid'))\n","\n","    return resnet18"],"metadata":{"execution":{"iopub.status.busy":"2023-06-10T20:52:46.943868Z","iopub.execute_input":"2023-06-10T20:52:46.944312Z","iopub.status.idle":"2023-06-10T20:52:46.974105Z","shell.execute_reply.started":"2023-06-10T20:52:46.944277Z","shell.execute_reply":"2023-06-10T20:52:46.972482Z"},"trusted":true,"id":"zXYpbENYrWYn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**NORMAL**"],"metadata":{"id":"3xNGGS-wrWYo"}},{"cell_type":"code","source":["checkpoint_callback_auc1 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/normal_auc1/',\n","                                                             save_weights_only=True,\n","                                                             monitor='val_AUC_1',\n","                                                             mode='max',\n","                                                             save_best_only=True)\n","checkpoint_callback_auc2 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/normal_auc2/',\n","                                                             save_weights_only=True,\n","                                                             monitor='val_AUC_2',\n","                                                             mode='max',\n","                                                             save_best_only=True)\n","checkpoint_callback_auc3 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/normal_auc3/',\n","                                                             save_weights_only=True,\n","                                                             monitor='val_AUC_3',\n","                                                             mode='max',\n","                                                             save_best_only=True)\n","checkpoint_callback_auc4 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/normal_auc4/',\n","                                                             save_weights_only=True,\n","                                                             monitor='val_AUC_4',\n","                                                             mode='max',\n","                                                             save_best_only=True)\n","checkpoint_callback_auc5 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/normal_auc5/',\n","                                                             save_weights_only=True,\n","                                                             monitor='val_AUC_5',\n","                                                             mode='max',\n","                                                             save_best_only=True)\n","\n","callbacks_list = [checkpoint_callback_auc1,\n","                  checkpoint_callback_auc2,\n","                  checkpoint_callback_auc3,\n","                  checkpoint_callback_auc4,\n","                  checkpoint_callback_auc5]\n","\n","def lr_scheduler(epoch, lr):\n","    return lr*0.9\n","\n","lr_decay_function = keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=0)"],"metadata":{"execution":{"iopub.status.busy":"2023-06-09T21:23:41.580405Z","iopub.execute_input":"2023-06-09T21:23:41.580788Z","iopub.status.idle":"2023-06-09T21:23:41.591117Z","shell.execute_reply.started":"2023-06-09T21:23:41.580760Z","shell.execute_reply":"2023-06-09T21:23:41.589845Z"},"trusted":true,"id":"5JdaJE1TrWYp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["histories = []\n","n_splits = 5\n","skf = model_selection.StratifiedShuffleSplit(n_splits=n_splits, random_state=314, train_size=0.85)\n","for number_of_split, data in enumerate(skf.split(X_train, y_train)):\n","    print(f'SPLIT {number_of_split+1}/{n_splits}:')\n","    train = [path + dirs[i] for i in data[0]]\n","    val = [path + dirs[j] for j in data[1]]\n","\n","    # Generators\n","    training_generator = DataGenerator(list_IDs=train,\n","                                       labels_dir='/kaggle/input/labelsssss/labels.csv',\n","                                       dim_img=(192, 256),\n","                                       batch_size=5,\n","                                       sub_batch_size=400,\n","                                       shuffle=True,\n","                                       training=True)\n","\n","    validation_generator = DataGenerator(list_IDs=val,\n","                                         labels_dir='/kaggle/input/labelsssss/labels.csv',\n","                                         dim_img=(192, 256),\n","                                         batch_size=1,\n","                                         sub_batch_size='IGNORED', #this argument will be ignored because training is false.\n","                                         shuffle=True,\n","                                         training=False)\n","\n","    resnet = get_resnet18()\n","\n","    resnet.compile(loss='binary_crossentropy',\n","                     optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n","                     metrics=[keras.metrics.AUC(name=f'AUC_{number_of_split+1}'),\n","                              keras.metrics.BinaryAccuracy(name='accuracy'),\n","                              keras.metrics.Precision(name='precision'),\n","                              keras.metrics.Recall(name='recall')])\n","\n","\n","    # Train model on dataset\n","    histories.append(resnet.fit(training_generator,\n","                                   validation_data=validation_generator,\n","                                   epochs=35,\n","                                   use_multiprocessing=True,\n","                                   workers=1,\n","                                   callbacks=[callbacks_list[number_of_split], lr_decay_function]))\n","    print('\\n')\n","    collect()"],"metadata":{"execution":{"iopub.status.busy":"2023-06-09T21:23:44.820422Z","iopub.execute_input":"2023-06-09T21:23:44.820812Z","iopub.status.idle":"2023-06-10T00:56:47.853993Z","shell.execute_reply.started":"2023-06-09T21:23:44.820783Z","shell.execute_reply":"2023-06-10T00:56:47.851945Z"},"trusted":true,"id":"tu7LpwQerWYp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(25, 50))\n","plt.subplot(4, 2, 1)\n","for i, h in enumerate(histories):\n","    plt.plot(list(range(1, 36)), h.history['loss'], marker='o')\n","    plt.title('SE ResNET-18 Loss evolution - Training: Normal vs others classes')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('Loss on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n","\n","plt.subplot(4, 2, 2)\n","for i, h in enumerate(histories):\n","    plt.plot(list(range(1, 36)), h.history['val_loss'], marker='o')\n","    plt.title('SE ResNET-18 Loss evolution - Validations: Normal vs others classes')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('Loss on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n","\n","plt.subplot(4, 2, 3)\n","for i, h in enumerate(histories):\n","    plt.plot(list(range(1, 36)), h.history['accuracy'], marker='o')\n","    plt.title('SE ResNET-18 Accuracy evolution - Training: Normal vs others classes')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('Accuracy on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n","\n","plt.subplot(4, 2, 4)\n","for i, h in enumerate(histories):\n","    plt.plot(list(range(1, 36)), h.history['val_accuracy'], marker='o')\n","    plt.title('SE ResNET-18 Accuracy evolution - Validations: Normal vs others classes')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('Accuracy on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n","\n","plt.subplot(4, 2, 5)\n","for i, h in enumerate(histories):\n","    plt.plot(list(range(1, 36)), h.history['recall'], marker='o')\n","    plt.title('SE ResNET-18 Recall evolution - Training: Normal vs others classes')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('Recall on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n","\n","plt.subplot(4, 2, 6)\n","for i, h in enumerate(histories):\n","    plt.plot(list(range(1, 36)), h.history['val_recall'], marker='o')\n","    plt.title('SE ResNET-18 Recall evolution - Validations: Normal vs others classes')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('Recall on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n","\n","plt.subplot(4, 2, 7)\n","for i, h in enumerate(histories):\n","    key_auc = f\"AUC_{i+1}\"\n","    plt.plot(list(range(1, 36)), h.history[key_auc], marker='o')\n","    plt.title('SE ResNET-18 AUC evolution - Training: Normal vs others classes')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('AUC on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n","\n","plt.subplot(4, 2, 8)\n","for i, h in enumerate(histories):\n","    key_auc_val = f\"val_AUC_{i+1}\"\n","    plt.plot(list(range(1, 36)), h.history[key_auc_val], marker='o')\n","    plt.title('SE ResNET-18 AUC evolution - Validations: Normal vs others classes')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('AUC on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])"],"metadata":{"execution":{"iopub.status.busy":"2023-06-10T00:56:47.860033Z","iopub.execute_input":"2023-06-10T00:56:47.860365Z","iopub.status.idle":"2023-06-10T00:56:51.160518Z","shell.execute_reply.started":"2023-06-10T00:56:47.860333Z","shell.execute_reply":"2023-06-10T00:56:51.159423Z"},"trusted":true,"id":"1X8IWJ_WrWYq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Best results in validations for any k-fold: ')\n","for i, h in enumerate(histories):\n","    print(f'K-FOLD {i+1}:')\n","    print(\"TRAINING RESULTS:\")\n","    k = np.max(h.history[f'AUC_{i+1}'])\n","    print(f'Best AUC in train: {k}')\n","    k = np.max(h.history[f'accuracy'])\n","    print(f'Best Accuracy in train: {k}')\n","    k = np.max(h.history[f'precision'])\n","    print(f'Best Precision in train: {k}')\n","    k = np.max(h.history[f'recall'])\n","    print(f'Best Recall in train: {k}')\n","\n","    print(\"\\nVALIDATION RESULTS:\")\n","    k = np.max(h.history[f'val_AUC_{i+1}'])\n","    print(f'Best AUC in validation: {k}')\n","    k = np.max(h.history[f'val_accuracy'])\n","    print(f'Best Accuracy in validation: {k}')\n","    k = np.max(h.history[f'val_precision'])\n","    print(f'Best Precision in validation: {k}')\n","    k = np.max(h.history[f'val_recall'])\n","    print(f'Best Recall in validation: {k}')\n","    print()\n","    print(f'{50*\"=\"}')\n","    print()\n","\n","results = np.empty((4, 5))\n","for i, h in enumerate(histories):\n","    results[0][i] = np.max(h.history[f'val_AUC_{i+1}'])\n","    results[1][i] = np.max(h.history['val_accuracy'])\n","    results[2][i] = np.max(h.history['val_precision'])\n","    results[3][i] = np.max(h.history['val_recall'])\n","\n","print(f\"Average best AUC: {np.mean(results[0])}\")\n","print(f\"standard deviation AUC: {np.std(results[0])}\\n\")\n","print(f\"Average best Accuracy: {np.mean(results[1])}\")\n","print(f\"Standard Deviation Accuracy: {np.std(results[1])}\\n\")\n","print(f\"Average best Precision: {np.mean(results[2])}\")\n","print(f\"Standard Deviation Precision: {np.std(results[2])}\\n\")\n","print(f\"Average best Recall: {np.mean(results[3])}\")\n","print(f\"Standard Deviation Recall: {np.std(results[3])}\\n\")\n"],"metadata":{"execution":{"iopub.status.busy":"2023-06-10T00:56:51.161595Z","iopub.execute_input":"2023-06-10T00:56:51.162433Z","iopub.status.idle":"2023-06-10T00:56:51.180477Z","shell.execute_reply.started":"2023-06-10T00:56:51.162398Z","shell.execute_reply":"2023-06-10T00:56:51.179555Z"},"trusted":true,"id":"ukYrc2ORrWYr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**TESTS**"],"metadata":{"id":"olwW1h04rWYw"}},{"cell_type":"code","source":["training_generator = DataGenerator(objective=[0, 0, 0, 1],\n","                                       list_IDs=X_train,\n","                                       labels_dir='/kaggle/input/labelsssss/labels.csv',\n","                                       dim_img=(192, 256),\n","                                       batch_size=5,\n","                                       sub_batch_size=400,\n","                                       shuffle=True,\n","                                       training=True)\n","\n","resnet = get_resnet18()\n","\n","resnet.compile(loss='binary_crossentropy',\n","                  optimizer=keras.optimizers.Adam(8e-7),\n","                  metrics=[keras.metrics.AUC(name='AUC'),\n","                           keras.metrics.BinaryAccuracy(name='accuracy'),\n","                           keras.metrics.Precision(name='precision'),\n","                           keras.metrics.Recall(name='recall')])\n","\n","\n","# Train model on dataset\n","resnet.load_weights('/kaggle/working/models/cancer_auc4/') #start with best AUC in validations\n","history = resnet.fit(training_generator, epochs=10)"],"metadata":{"execution":{"iopub.status.busy":"2023-06-10T21:24:53.536012Z","iopub.execute_input":"2023-06-10T21:24:53.536989Z","iopub.status.idle":"2023-06-10T21:31:37.851668Z","shell.execute_reply.started":"2023-06-10T21:24:53.536953Z","shell.execute_reply":"2023-06-10T21:31:37.850639Z"},"trusted":true,"id":"-COt9UUQrWY0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["res = []\n","for x in X_test:\n","    x = np.load(x)\n","    x = np.array(separate_slices(x))\n","    pred = resnet.predict(np.array(x), verbose=0)\n","    res.append(np.argmax(pred))\n","print(res)"],"metadata":{"execution":{"iopub.status.busy":"2023-06-10T21:31:37.853389Z","iopub.execute_input":"2023-06-10T21:31:37.853840Z","iopub.status.idle":"2023-06-10T21:32:05.859580Z","shell.execute_reply.started":"2023-06-10T21:31:37.853804Z","shell.execute_reply":"2023-06-10T21:32:05.858578Z"},"trusted":true,"id":"TGfsin82rWY0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["matrix_confusion = np.array([[0, 0, 0, 0],\n","                             [0, 0, 0, 0],\n","                             [0, 0, 0, 0],\n","                             [0, 0, 0, 0]])\n","\n","for y_pred, y_true in zip(res, y_test):\n","    matrix_confusion[y_pred][y_true] += 1\n","\n","print(matrix_confusion)"],"metadata":{"execution":{"iopub.status.busy":"2023-06-10T21:32:05.861161Z","iopub.execute_input":"2023-06-10T21:32:05.861507Z","iopub.status.idle":"2023-06-10T21:32:05.868659Z","shell.execute_reply.started":"2023-06-10T21:32:05.861475Z","shell.execute_reply":"2023-06-10T21:32:05.867519Z"},"trusted":true,"id":"VXxbqpE4rWY1"},"execution_count":null,"outputs":[]}]}