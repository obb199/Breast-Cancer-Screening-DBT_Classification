{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import cv2\n","from tensorflow import keras\n","import os\n","from sklearn import model_selection\n","from sklearn import utils\n","from sklearn.metrics import confusion_matrix, roc_curve, RocCurveDisplay, roc_auc_score\n","from scipy import ndimage\n","from gc import collect\n","import matplotlib.pyplot as plt\n","from collections import Counter\n","from seaborn import heatmap"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T16:59:39.578890Z","iopub.execute_input":"2023-08-11T16:59:39.579495Z","iopub.status.idle":"2023-08-11T16:59:49.663147Z","shell.execute_reply.started":"2023-08-11T16:59:39.579460Z","shell.execute_reply":"2023-08-11T16:59:49.662209Z"},"trusted":true,"id":"16iaN3qgpN-6","outputId":"f8424a6a-fd14-4887-8645-ee4c250d5f08"},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":["def get_labels(label_file):\n","    \"\"\"lê a tabela com as informações dos pacientes e retorna uma matriz com o ID e as labels\"\"\"\n","    labels = pd.read_csv(label_file)\n","    cancer_labels = dict()\n","\n","    for p in labels.index:\n","        cancer_labels[labels['PatientID'][p]] = [int(labels['Normal'][p]), int(labels['Actionable'][p]), int(labels['Benign'][p]), int(labels['Cancer'][p])]\n","\n","    return cancer_labels"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T17:00:23.133983Z","iopub.execute_input":"2023-08-11T17:00:23.134619Z","iopub.status.idle":"2023-08-11T17:00:23.141757Z","shell.execute_reply.started":"2023-08-11T17:00:23.134585Z","shell.execute_reply":"2023-08-11T17:00:23.140689Z"},"trusted":true,"id":"whO6dEPkpN-9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels = get_labels('/kaggle/input/labelsssss/labels.csv')\n","numbers_per_class = [0, 0, 0, 0]\n","for i in labels:\n","    numbers_per_class[np.argmax(labels[i])] += 1\n","\n","proportion_per_class = [round(number_of_class/sum(numbers_per_class), 2) for number_of_class in numbers_per_class]\n","proportion_per_class"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T17:00:25.847719Z","iopub.execute_input":"2023-08-11T17:00:25.848076Z","iopub.status.idle":"2023-08-11T17:00:25.919785Z","shell.execute_reply.started":"2023-08-11T17:00:25.848044Z","shell.execute_reply":"2023-08-11T17:00:25.918863Z"},"trusted":true,"id":"RfYlplnopN-9","outputId":"b603efd1-56dc-4fcf-c77e-962689ef9272"},"execution_count":null,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"[0.35, 0.25, 0.23, 0.17]"},"metadata":{}}]},{"cell_type":"code","source":["path = '/kaggle/input/192x256xdepth/'\n","dirs = os.listdir(path)\n","\n","X = [path + i for i in os.listdir(path)]\n","y = [np.argmax(labels[(path+i)[-14:-4]]) for i in os.listdir(path)]"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T17:00:28.047367Z","iopub.execute_input":"2023-08-11T17:00:28.047728Z","iopub.status.idle":"2023-08-11T17:00:28.167308Z","shell.execute_reply.started":"2023-08-11T17:00:28.047697Z","shell.execute_reply":"2023-08-11T17:00:28.166213Z"},"trusted":true,"id":"Rw52MRqrpN-9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def balancing_batch(X, y, max_value):\n","    numbers_per_class = sorted(Counter(y).items())\n","\n","    if len(numbers_per_class) == 1:\n","        return X[0:1], y[0:1] #return only the first image because the batch has only one class\n","\n","    X, y = utils.shuffle(X, y)\n","    new_X, new_y = [], []\n","    counter_class_zero = 0\n","    counter_class_one = 0\n","    counter_class_two = 0\n","    counter_class_three = 0\n","\n","    max_per_class = int(max_value/4)\n","\n","    for test_x, test_y in zip(X, y):\n","        if test_y == 0 and counter_class_zero < max_per_class:\n","            new_X.append(test_x)\n","            new_y.append(test_y)\n","            counter_class_zero += 1\n","        elif test_y == 1 and counter_class_one < max_per_class:\n","            new_X.append(test_x)\n","            new_y.append(test_y)\n","            counter_class_one += 1\n","        elif test_y == 2 and counter_class_two < max_per_class:\n","            new_X.append(test_x)\n","            new_y.append(test_y)\n","            counter_class_two += 1\n","        elif test_y == 3 and counter_class_three < max_per_class:\n","            new_X.append(test_x)\n","            new_y.append(test_y)\n","            counter_class_three += 1\n","\n","    return np.array(new_X, dtype='float16'), np.array(new_y, dtype='uint8')"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T17:00:30.639201Z","iopub.execute_input":"2023-08-11T17:00:30.639571Z","iopub.status.idle":"2023-08-11T17:00:30.649638Z","shell.execute_reply.started":"2023-08-11T17:00:30.639539Z","shell.execute_reply":"2023-08-11T17:00:30.648588Z"},"trusted":true,"id":"_fULyI7zpN--"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def separate_slices(img):\n","    'function to separate 2d images of 3d original image'\n","    slices = []\n","\n","    for i in range(img.shape[-2]):\n","        slices.append(np.array(img[:, :, i]))\n","\n","    slices.append(np.mean(img, axis=-2)) #including mean of slices\n","\n","    return slices"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T17:00:33.070399Z","iopub.execute_input":"2023-08-11T17:00:33.070754Z","iopub.status.idle":"2023-08-11T17:00:33.077040Z","shell.execute_reply.started":"2023-08-11T17:00:33.070725Z","shell.execute_reply":"2023-08-11T17:00:33.076121Z"},"trusted":true,"id":"ArT8Ak7EpN-_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, stratify=y,random_state=42, train_size=0.8)"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T17:00:35.943869Z","iopub.execute_input":"2023-08-11T17:00:35.944329Z","iopub.status.idle":"2023-08-11T17:00:35.955346Z","shell.execute_reply.started":"2023-08-11T17:00:35.944288Z","shell.execute_reply":"2023-08-11T17:00:35.954230Z"},"trusted":true,"id":"j6k6RD03pN-_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DataGenerator(tf.keras.utils.Sequence):\n","    'Generates data for Keras'\n","    def __init__(self, list_IDs, labels_dir, batch_size, sub_batch_size, dim_img, training, shuffle=True):\n","        self.list_IDs = list_IDs # array of strings with original images name with directory\n","        self.labels = self.__get_labels(labels_dir) #dict with labels of all images\n","        self.batch_size = batch_size #3d-images per batch\n","        self.sub_batch_size = sub_batch_size #quantity of sub-images per batch will be choose to train\n","        self.dim_img = dim_img # tuple with width and height of image like (192, 256)\n","        self.training = training # true if generator is for training, false if generator is for validation\n","        self.shuffle = shuffle # true or false to shuffle data after any epochs\n","        self.on_epoch_end() # call of the function\n","\n","\n","    def __get_labels(self, label_file):\n","        'take the dict with labels of images'\n","        labels = pd.read_csv(label_file)\n","        cancer_labels = dict()\n","\n","        for p in labels.index:\n","            cancer_labels[labels['PatientID'][p]] = [int(labels['Normal'][p]), int(labels['Actionable'][p]), int(labels['Benign'][p]), int(labels['Cancer'][p])]\n","\n","        return cancer_labels\n","\n","    def __data_augmentation(self, x):\n","        'generate variations of images'\n","        new_images = []\n","        x = x.astype('float16')\n","        new_images.append(x)\n","\n","        x = cv2.flip(x.astype('float32'), 1).astype('float16')\n","\n","        new_images.append(np.expand_dims(x, -1))\n","\n","        return utils.shuffle(new_images)\n","\n","    def __len__(self):\n","        'Denotes the number of batches per epoch'\n","        return int(np.floor(len(self.list_IDs) / self.batch_size))\n","\n","\n","    def __getitem__(self, index):\n","        'Generate one batch of data'\n","        # Generate indexes of the batch\n","        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","\n","        # Find list of IDs\n","        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n","\n","        # Generate data\n","        X, y = self.__data_generation(list_IDs_temp)\n","\n","        if self.training:\n","            X, y = balancing_batch(X, y, self.sub_batch_size)\n","            return np.array(X[0:self.sub_batch_size], dtype='float16'), np.array(y[0:self.sub_batch_size], dtype='uint8')\n","\n","        return np.array(X), np.array(y)\n","\n","    def on_epoch_end(self):\n","        'Updates indexes after each epoch'\n","        self.indexes = np.arange(len(self.list_IDs))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","\n","    def __data_generation(self, list_IDs_temp):\n","        'Generates data containing batch_size samples'\n","        X = []\n","        y = []\n","\n","        # Generate data\n","        for i, ID in enumerate(list_IDs_temp):\n","            # Store sample\n","            prev_len_X = len(X)\n","            full_image = np.load(ID)\n","            new_images = separate_slices(full_image)\n","            if self.training:\n","                for img in new_images:\n","                    X += self.__data_augmentation(img)\n","            else:\n","                X = np.array(new_images, dtype='float16')\n","\n","            #adding new data labels for y array\n","            for _ in range(len(X) - prev_len_X):\n","                y.append(self.labels[ID[-14:-4]]) #'-14:-4 represent a part of string with name of original image that slices was taken'\n","\n","        X, y = utils.shuffle(X, y)\n","        return X, y"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T17:00:39.161069Z","iopub.execute_input":"2023-08-11T17:00:39.161494Z","iopub.status.idle":"2023-08-11T17:00:39.179725Z","shell.execute_reply.started":"2023-08-11T17:00:39.161462Z","shell.execute_reply":"2023-08-11T17:00:39.178587Z"},"trusted":true,"id":"r1Bjmf-QpN-_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class InceptionModule_a(keras.layers.Layer):\n","    def __init__(self, activation='relu', **kwargs):\n","        super().__init__(**kwargs)\n","        self.activation = keras.activations.get('relu')\n","\n","        self.conv_a1    = keras.layers.Conv2D(64, kernel_size=(1,1), padding='same', strides=1)\n","        self.bn_a1      = keras.layers.BatchNormalization()\n","        self.conv_a2    = keras.layers.Conv2D(96, kernel_size=(3,3), padding='same', strides=1)\n","        self.bn_a2      = keras.layers.BatchNormalization()\n","        self.conv_a3    = keras.layers.Conv2D(96, kernel_size=(3,3), padding='same', strides=1)\n","        self.bn_a3      = keras.layers.BatchNormalization()\n","\n","        self.conv_b1    = keras.layers.Conv2D(48, kernel_size=(1, 1), padding='same', strides=1)\n","        self.conv_b2    = keras.layers.Conv2D(48, kernel_size=(3, 3), padding='same', strides=1)\n","        self.bn_b1      = keras.layers.BatchNormalization()\n","\n","        self.maxpool_c  = keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same', strides=1)\n","        self.conv_c1    = keras.layers.Conv2D(32, kernel_size=(1, 1), padding='same', strides=1)\n","        self.bn_c1      = keras.layers.BatchNormalization()\n","\n","        self.conv_d1    = keras.layers.Conv2D(64, kernel_size=(1, 1), padding='same', strides=1)\n","        self.bn_d       = keras.layers.BatchNormalization()\n","\n","    def call(self, x):\n","        out1 = self.conv_a1(x)\n","        out1 = self.bn_a1(out1)\n","        out1 = self.conv_a2(out1)\n","        out1 = self.bn_a2(out1)\n","        out1 = self.conv_a3(out1)\n","        out1 = self.bn_a3(out1)\n","        out1 = self.activation(out1)\n","\n","        out2 = self.conv_b1(x)\n","        out2 = self.conv_b2(out2)\n","        out2 = self.bn_b1(out2)\n","        out2 = self.activation(out2)\n","\n","        out3 = self.maxpool_c(x)\n","        out3 = self.conv_c1(out3)\n","        out3 = self.bn_c1(out3)\n","        out3 = self.activation(out3)\n","\n","        out4 = self.conv_d1(x)\n","        out4 = self.bn_d(out4)\n","        out4 = self.activation(out4)\n","\n","        return tf.concat([out1, out2, out3, out4], axis=3)\n","\n","class InceptionReduction_a(keras.layers.Layer):\n","    def __init__(self, activation='relu', **kwargs):\n","        super().__init__(**kwargs)\n","        self.activation = keras.activations.get('relu')\n","\n","        self.maxpool_a  = keras.layers.MaxPooling2D(pool_size=(2), padding='same')\n","\n","        self.conv_b1 = keras.layers.Conv2D(384, kernel_size=(2, 4), padding='same', strides=2)\n","        self.bn_b1    = keras.layers.BatchNormalization()\n","\n","        self.conv_c1 = keras.layers.Conv2D(64, kernel_size=(1,1), padding='same')\n","        self.conv_c2 = keras.layers.Conv2D(96, kernel_size=(2,4), padding='same')\n","        self.bn_c1   = keras.layers.BatchNormalization()\n","        self.conv_c3 = keras.layers.Conv2D(96, kernel_size=(2,4), padding='same', strides=2)\n","        self.bn_c2   = keras.layers.BatchNormalization()\n","\n","    def call(self, x):\n","        out1 = self.maxpool_a(x)\n","        out1 = self.activation(out1)\n","\n","        out2 = self.conv_b1(x)\n","        out2 = self.bn_b1(out2)\n","        out2 = self.activation(out2)\n","\n","        out3 = self.conv_c1(x)\n","        out3 = self.conv_c2(out3)\n","        out3 = self.bn_c1(out3)\n","        out3 = self.conv_c3(out3)\n","        out3 = self.bn_c2(out3)\n","        out3 = self.activation(out3)\n","\n","        return tf.concat([out1, out2, out3], axis=3)\n","\n","class InceptionModule_b(keras.layers.Layer):\n","    def __init__(self, activation='relu', **kwargs):\n","        super().__init__(**kwargs)\n","        self.activation = keras.activations.get('relu')\n","\n","        self.conv_a1   = keras.layers.Conv2D(128, kernel_size=(1,1), padding='same', strides=1)\n","        self.conv_a2   = keras.layers.Conv2D(128, kernel_size=(1,7), padding='same', strides=1)\n","        self.bn_a1     = keras.layers.BatchNormalization()\n","        self.conv_a3   = keras.layers.Conv2D(128, kernel_size=(7,1), padding='same', strides=1)\n","        self.bn_a2     = keras.layers.BatchNormalization()\n","        self.conv_a4   = keras.layers.Conv2D(128, kernel_size=(1,7), padding='same', strides=1)\n","        self.bn_a3     = keras.layers.BatchNormalization()\n","        self.conv_a5   = keras.layers.Conv2D(192, kernel_size=(7,1), padding='same', strides=1)\n","        self.bn_a4     = keras.layers.BatchNormalization()\n","\n","        self.conv_b1   = keras.layers.Conv2D(128, kernel_size=(1, 1), padding='same', strides=1)\n","        self.conv_b2   = keras.layers.Conv2D(128, kernel_size=(7, 1), padding='same', strides=1)\n","        self.bn_b1     = keras.layers.BatchNormalization()\n","        self.conv_b3   = keras.layers.Conv2D(192, kernel_size=(1, 7), padding='same', strides=1)\n","        self.bn_b2     = keras.layers.BatchNormalization()\n","\n","        self.maxpool_c = keras.layers.MaxPooling2D(pool_size=(2), padding='same', strides=1)\n","        self.conv_c1   = keras.layers.Conv2D(192, kernel_size=(1, 1), padding='same', strides=1)\n","        self.bn_c1     = keras.layers.BatchNormalization()\n","\n","        self.conv_d1    = keras.layers.Conv2D(192, kernel_size=(1, 1), padding='same', strides=1)\n","        self.bn_d1      = keras.layers.BatchNormalization()\n","\n","    def call(self, x):\n","        out1 = self.conv_a1(x)\n","        out1 = self.conv_a2(out1)\n","        out1 = self.bn_a1(out1)\n","        out1 = self.conv_a3(out1)\n","        out1 = self.bn_a2(out1)\n","        out1 = self.conv_a4(out1)\n","        out1 = self.bn_a3(out1)\n","        out1 = self.conv_a5(out1)\n","        out1 = self.bn_a4(out1)\n","        out1 = self.activation(out1)\n","\n","        out2 = self.conv_b1(x)\n","        out2 = self.conv_b2(out2)\n","        out2 = self.bn_b1(out2)\n","        out2 = self.conv_b3(out2)\n","        out2 = self.bn_b2(out2)\n","        out2 = self.activation(out2)\n","\n","        out3 = self.maxpool_c(x)\n","        out3 = self.conv_c1(out3)\n","        out3 = self.bn_c1(out3)\n","        out4 = self.activation(out3)\n","\n","        out4 = self.conv_d1(x)\n","        out4 = self.bn_d1(out4)\n","        out4 = self.activation(out4)\n","\n","        return tf.concat([out1, out2, out3, out4], axis=3)\n","\n","class InceptionReduction_b(keras.layers.Layer):\n","    def __init__(self, activation='relu', **kwargs):\n","        super().__init__(**kwargs)\n","        self.activation = keras.activations.get('relu')\n","\n","        self.maxpool_a  = keras.layers.MaxPooling2D(pool_size=(2), padding='same', strides=2)\n","\n","        self.conv_b1 = keras.layers.Conv2D(192, kernel_size=(1,1), padding='same')\n","        self.conv_b2 = keras.layers.Conv2D(320, kernel_size=(2,4), padding='same', strides=2)\n","        self.bn_b    = keras.layers.BatchNormalization()\n","\n","        self.conv_c1 = keras.layers.Conv2D(192, kernel_size=(1,1), padding='same')\n","        self.conv_c2 = keras.layers.Conv2D(192, kernel_size=(1,7), padding='same')\n","        self.bn_c1   = keras.layers.BatchNormalization()\n","        self.conv_c3 = keras.layers.Conv2D(192, kernel_size=(7,1), padding='same')\n","        self.bn_c2   = keras.layers.BatchNormalization()\n","        self.conv_c4 = keras.layers.Conv2D(192, kernel_size=(2, 4), padding='same', strides=2)\n","        self.bn_c3   = keras.layers.BatchNormalization()\n","\n","    def call(self, x):\n","        out1 = self.maxpool_a(x)\n","        out1 = self.activation(out1)\n","\n","        out2 = self.conv_b1(x)\n","        out2 = self.conv_b2(out2)\n","        out2 = self.bn_b(out2)\n","        out2 = self.activation(out2)\n","\n","        out3 = self.conv_c1(x)\n","        out3 = self.conv_c2(out3)\n","        out3 = self.bn_c1(out3)\n","        out3 = self.conv_c3(out3)\n","        out3 = self.bn_c2(out3)\n","        out3 = self.conv_c4(out3)\n","        out3 = self.bn_c3(out3)\n","        out3 = self.activation(out3)\n","\n","        return tf.concat([out1, out2, out3], axis=3)\n","\n","class InceptionModule_c(keras.layers.Layer):\n","    def __init__(self, activation='relu', **kwargs):\n","        super().__init__(**kwargs)\n","        self.activation = keras.activations.get('relu')\n","\n","        self.conv_a1   = keras.layers.Conv2D(192, kernel_size=(1,1), padding='same')\n","        self.conv_a2   = keras.layers.Conv2D(192, kernel_size=(3,3), padding='same')\n","        self.bn_a1     = keras.layers.BatchNormalization()\n","        self.conv_a11  = keras.layers.Conv2D(192, kernel_size=(1,3), padding='same', strides=2)\n","        self.bn_a11    = keras.layers.BatchNormalization()\n","        self.conv_a12  = keras.layers.Conv2D(192, kernel_size=(3,1), padding='same',strides=2)\n","        self.bn_a12    = keras.layers.BatchNormalization()\n","\n","        self.conv_a1   = keras.layers.Conv2D(192, kernel_size=(1,1), padding='same')\n","        self.bn_a1     = keras.layers.BatchNormalization()\n","        self.conv_a11  = keras.layers.Conv2D(192, kernel_size=(1,3), padding='same', strides=2)\n","        self.bn_a11    = keras.layers.BatchNormalization()\n","        self.conv_a12  = keras.layers.Conv2D(192, kernel_size=(3,1), padding='same', strides=2)\n","        self.bn_a12    = keras.layers.BatchNormalization()\n","\n","        self.maxpool_c = keras.layers.MaxPooling2D(pool_size=(2), padding='same')\n","        self.conv_c1   = keras.layers.Conv2D(192, kernel_size=(1, 1), padding='same')\n","        self.bn_c      = keras.layers.BatchNormalization()\n","\n","        self.conv_d    = keras.layers.Conv2D(384, kernel_size=(1, 1), padding='same', strides=2)\n","        self.bn_d      = keras.layers.BatchNormalization()\n","\n","    def call(self, x):\n","        out1  = self.conv_a1(x)\n","        out1  = self.conv_a2(out1)\n","        out1  = self.bn_a1(out1)\n","        out11 = self.conv_a11(out1)\n","        out11 = self.bn_a11(out11)\n","        out11 = self.activation(out11)\n","        out12 = self.conv_a12(out1)\n","        out12 = self.bn_a12(out12)\n","        out11 = self.activation(out12)\n","\n","        out2 = self.conv_a1(x)\n","        out2 = self.bn_a1(out2)\n","        out21 = self.conv_a11(out2)\n","        out21 = self.bn_a11(out21)\n","        out21 = self.activation(out21)\n","        out22 = self.conv_a12(out2)\n","        out22 = self.bn_a12(out22)\n","        out22 = self.activation(out22)\n","\n","        out3 = self.maxpool_c(x)\n","        out3 = self.conv_c1(out3)\n","        out3 = self.bn_c(out3)\n","        out3 = self.activation(out3)\n","\n","        out4 = self.conv_d(x)\n","        out4 = self.bn_d(out4)\n","        out4 = self.activation(out4)\n","\n","        return tf.concat([out11, out12, out21, out22, out3, out4], axis=3)\n","\n","def get_inception_v3():\n","    Inception_v3 = keras.Sequential()\n","    Inception_v3.add(keras.layers.Conv2D(filters=32, kernel_size=(4,2), padding='valid', strides=2, input_shape=(192, 256, 1)))\n","    Inception_v3.add(keras.layers.BatchNormalization())\n","    Inception_v3.add(keras.layers.Conv2D(filters=32, kernel_size=(4,2), padding='valid', strides=1))\n","    Inception_v3.add(keras.layers.BatchNormalization())\n","    Inception_v3.add(keras.layers.Conv2D(filters=64, kernel_size=(4,2), padding='same', strides=1))\n","    Inception_v3.add(keras.layers.BatchNormalization())\n","    Inception_v3.add(keras.layers.MaxPooling2D(2))\n","    Inception_v3.add(keras.layers.Conv2D(filters=80, kernel_size=(4,2), padding='valid', strides=1))\n","    Inception_v3.add(keras.layers.BatchNormalization())\n","    Inception_v3.add(keras.layers.Conv2D(filters=192, kernel_size=(4,2), padding='valid', strides=2))\n","    Inception_v3.add(keras.layers.BatchNormalization())\n","    Inception_v3.add(InceptionModule_a())\n","    Inception_v3.add(InceptionModule_a())\n","    Inception_v3.add(InceptionModule_a())\n","    Inception_v3.add(InceptionReduction_a())\n","    Inception_v3.add(InceptionModule_b())\n","    Inception_v3.add(InceptionModule_b())\n","    Inception_v3.add(InceptionModule_b())\n","    Inception_v3.add(InceptionModule_b())\n","    Inception_v3.add(InceptionModule_b())\n","    Inception_v3.add(InceptionReduction_b())\n","    Inception_v3.add(InceptionModule_c())\n","    Inception_v3.add(InceptionModule_c())\n","    Inception_v3.add(keras.layers.GlobalAveragePooling2D())\n","    Inception_v3.add(keras.layers.Dense(2048, activation='relu'))\n","    Inception_v3.add(keras.layers.Dense(4, activation='sigmoid'))\n","\n","    return Inception_v3"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T17:00:43.666038Z","iopub.execute_input":"2023-08-11T17:00:43.666558Z","iopub.status.idle":"2023-08-11T17:00:43.729877Z","shell.execute_reply.started":"2023-08-11T17:00:43.666522Z","shell.execute_reply":"2023-08-11T17:00:43.728788Z"},"trusted":true,"id":"iJ2ImcFUpN_A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inception = get_inception_v3()\n","inception.summary()"],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T01:09:27.161200Z","iopub.execute_input":"2023-08-10T01:09:27.161554Z","iopub.status.idle":"2023-08-10T01:09:32.657061Z","shell.execute_reply.started":"2023-08-10T01:09:27.161526Z","shell.execute_reply":"2023-08-10T01:09:32.656277Z"},"trusted":true,"id":"cwfBhdU-pN_C","outputId":"9647dbab-77f1-431b-eff9-c838a2d115b8"},"execution_count":null,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 95, 128, 32)       288       \n                                                                 \n batch_normalization (BatchN  (None, 95, 128, 32)      128       \n ormalization)                                                   \n                                                                 \n conv2d_1 (Conv2D)           (None, 92, 127, 32)       8224      \n                                                                 \n batch_normalization_1 (Batc  (None, 92, 127, 32)      128       \n hNormalization)                                                 \n                                                                 \n conv2d_2 (Conv2D)           (None, 92, 127, 64)       16448     \n                                                                 \n batch_normalization_2 (Batc  (None, 92, 127, 64)      256       \n hNormalization)                                                 \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 46, 63, 64)       0         \n )                                                               \n                                                                 \n conv2d_3 (Conv2D)           (None, 43, 62, 80)        41040     \n                                                                 \n batch_normalization_3 (Batc  (None, 43, 62, 80)       320       \n hNormalization)                                                 \n                                                                 \n conv2d_4 (Conv2D)           (None, 20, 31, 192)       123072    \n                                                                 \n batch_normalization_4 (Batc  (None, 20, 31, 192)      768       \n hNormalization)                                                 \n                                                                 \n inception_module_a (Incepti  (None, 20, 31, 240)      200960    \n onModule_a)                                                     \n                                                                 \n inception_module_a_1 (Incep  (None, 20, 31, 240)      210944    \n tionModule_a)                                                   \n                                                                 \n inception_module_a_2 (Incep  (None, 20, 31, 240)      210944    \n tionModule_a)                                                   \n                                                                 \n inception_reduction_a (Ince  (None, 10, 16, 720)      878464    \n ptionReduction_a)                                               \n                                                                 \n inception_module_b (Incepti  (None, 10, 16, 768)      1270272   \n onModule_b)                                                     \n                                                                 \n inception_module_b_1 (Incep  (None, 10, 16, 768)      1300992   \n tionModule_b)                                                   \n                                                                 \n inception_module_b_2 (Incep  (None, 10, 16, 768)      1300992   \n tionModule_b)                                                   \n                                                                 \n inception_module_b_3 (Incep  (None, 10, 16, 768)      1300992   \n tionModule_b)                                                   \n                                                                 \n inception_module_b_4 (Incep  (None, 10, 16, 768)      1300992   \n tionModule_b)                                                   \n                                                                 \n inception_reduction_b (Ince  (None, 5, 8, 1280)       1602304   \n ptionReduction_b)                                               \n                                                                 \n inception_module_c (Incepti  (None, 3, 4, 1344)       1541952   \n onModule_c)                                                     \n                                                                 \n inception_module_c_1 (Incep  (None, 2, 2, 1344)       1591104   \n tionModule_c)                                                   \n                                                                 \n global_average_pooling2d (G  (None, 1344)             0         \n lobalAveragePooling2D)                                          \n                                                                 \n dense (Dense)               (None, 2048)              2754560   \n                                                                 \n dense_1 (Dense)             (None, 1)                 2049      \n                                                                 \n=================================================================\nTotal params: 15,658,193\nTrainable params: 15,634,641\nNon-trainable params: 23,552\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":["**NORMAL**"],"metadata":{"id":"B49PvdFipN_D"}},{"cell_type":"code","source":["checkpoint_callback_auc1 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/normal_auc1/',\n","                                                             save_weights_only=True,\n","                                                             monitor='val_AUC_1',\n","                                                             mode='max',\n","                                                             save_best_only=True)\n","checkpoint_callback_auc2 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/normal_auc2/',\n","                                                             save_weights_only=True,\n","                                                             monitor='val_AUC_2',\n","                                                             mode='max',\n","                                                             save_best_only=True)\n","checkpoint_callback_auc3 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/normal_auc3/',\n","                                                             save_weights_only=True,\n","                                                             monitor='val_AUC_3',\n","                                                             mode='max',\n","                                                             save_best_only=True)\n","checkpoint_callback_auc4 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/normal_auc4/',\n","                                                             save_weights_only=True,\n","                                                             monitor='val_AUC_4',\n","                                                             mode='max',\n","                                                             save_best_only=True)\n","checkpoint_callback_auc5 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/normal_auc5/',\n","                                                             save_weights_only=True,\n","                                                             monitor='val_AUC_5',\n","                                                             mode='max',\n","                                                             save_best_only=True)\n","\n","callbacks_list = [checkpoint_callback_auc1,\n","                  checkpoint_callback_auc2,\n","                  checkpoint_callback_auc3,\n","                  checkpoint_callback_auc4,\n","                  checkpoint_callback_auc5]\n","\n","def lr_scheduler(epoch, lr):\n","    return lr*0.9\n","\n","lr_decay_function = keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=0)"],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T12:29:43.816533Z","iopub.execute_input":"2023-08-10T12:29:43.817415Z","iopub.status.idle":"2023-08-10T12:29:43.826803Z","shell.execute_reply.started":"2023-08-10T12:29:43.817369Z","shell.execute_reply":"2023-08-10T12:29:43.825734Z"},"trusted":true,"id":"XI_bzE9wpN_E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["histories = []\n","n_splits = 5\n","skf = model_selection.StratifiedShuffleSplit(n_splits=n_splits, random_state=314, train_size=0.85)\n","for number_of_split, data in enumerate(skf.split(X_train, y_train)):\n","    print(f'SPLIT {number_of_split+1}/{n_splits}:')\n","    train = [path + dirs[i] for i in data[0]]\n","    val = [path + dirs[j] for j in data[1]]\n","\n","    # Generators\n","    training_generator = DataGenerator(list_IDs=train,\n","                                       labels_dir='/kaggle/input/labelsssss/labels.csv',\n","                                       dim_img=(192, 256),\n","                                       batch_size=5,\n","                                       sub_batch_size=400,\n","                                       shuffle=True,\n","                                       training=True)\n","\n","    validation_generator = DataGenerator(list_IDs=val,\n","                                         labels_dir='/kaggle/input/labelsssss/labels.csv',\n","                                         dim_img=(192, 256),\n","                                         batch_size=1,\n","                                         sub_batch_size='IGNORED', #this argument will be ignored because training is false.\n","                                         shuffle=True,\n","                                         training=False)\n","\n","    strategy = tf.distribute.MirroredStrategy()\n","    with strategy.scope():\n","        inception = get_inception_v3()\n","        inception.compile(loss='categorical_crossentropy',\n","                         optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n","                         metrics=[keras.metrics.AUC(name=f'AUC_{number_of_split+1}'),\n","                                  keras.metrics.CategoricalAccuracy(name='accuracy'),\n","                                  keras.metrics.Precision(name='precision'),\n","                                  keras.metrics.Recall(name='recall')])\n","\n","\n","    # Train model on dataset\n","    histories.append(inception.fit(training_generator,\n","                                   validation_data=validation_generator,\n","                                   epochs=35,\n","                                   use_multiprocessing=True,\n","                                   workers=1,\n","                                   callbacks=[callbacks_list[number_of_split], lr_decay_function]))\n","    print('\\n')\n","    collect()"],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T12:29:48.106941Z","iopub.execute_input":"2023-08-10T12:29:48.107303Z","iopub.status.idle":"2023-08-10T17:15:33.619578Z","shell.execute_reply.started":"2023-08-10T12:29:48.107275Z","shell.execute_reply":"2023-08-10T17:15:33.615247Z"},"trusted":true,"id":"M1zuXTInpN_F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(25, 50))\n","plt.subplot(4, 2, 1)\n","for i, h in enumerate(histories):\n","    plt.plot(list(range(1, 36)), h.history['loss'], marker='o')\n","    plt.title('Loss evolution - Training')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('Loss on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n","\n","plt.subplot(4, 2, 2)\n","for i, h in enumerate(histories):\n","    plt.plot(list(range(1, 36)), h.history['val_loss'], marker='o')\n","    plt.title('Inception-V3 Loss evolution - Validations')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('Loss on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n","\n","plt.subplot(4, 2, 3)\n","for i, h in enumerate(histories):\n","    plt.plot(list(range(1, 36)), h.history['accuracy'], marker='o')\n","    plt.title('Inception-V3 Accuracy evolution - Training')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('Accuracy on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n","\n","plt.subplot(4, 2, 4)\n","for i, h in enumerate(histories):\n","    plt.plot(list(range(1, 36)), h.history['val_accuracy'], marker='o')\n","    plt.title('Inception-V3 Accuracy evolution - Validations')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('Accuracy on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n","\n","plt.subplot(4, 2, 5)\n","for i, h in enumerate(histories):\n","    plt.plot(list(range(1, 36)), h.history['recall'], marker='o')\n","    plt.title('Inception-V3 Recall evolution - Training')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('Recall on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n","\n","plt.subplot(4, 2, 6)\n","for i, h in enumerate(histories):\n","    plt.plot(list(range(1, 36)), h.history['val_recall'], marker='o')\n","    plt.title('Inception-V3 Recall evolution - Validations')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('Recall on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n","\n","plt.subplot(4, 2, 7)\n","for i, h in enumerate(histories):\n","    key_auc = f\"AUC_{i+1}\"\n","    plt.plot(list(range(1, 36)), h.history[key_auc], marker='o')\n","    plt.title('Inception-V3 AUC evolution - Training')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('AUC on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n","\n","plt.subplot(4, 2, 8)\n","for i, h in enumerate(histories):\n","    key_auc_val = f\"val_AUC_{i+1}\"\n","    plt.plot(list(range(1, 36)), h.history[key_auc_val], marker='o')\n","    plt.title('Inception-V3 AUC evolution - Validations')\n","    plt.xlabel('epoch number')\n","    plt.ylabel('AUC on epoch')\n","    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])"],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T17:15:33.633026Z","iopub.execute_input":"2023-08-10T17:15:33.633555Z","iopub.status.idle":"2023-08-10T17:15:38.886804Z","shell.execute_reply.started":"2023-08-10T17:15:33.633491Z","shell.execute_reply":"2023-08-10T17:15:38.885650Z"},"trusted":true,"id":"34ULc7UGpN_F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Best results in validations for any k-fold: ')\n","for i, h in enumerate(histories):\n","    print(f'K-FOLD {i+1}:')\n","    print(\"TRAINING RESULTS:\")\n","    k = np.max(h.history[f'AUC_{i+1}'])\n","    print(f'Best AUC in train: {k}')\n","    k = np.max(h.history[f'accuracy'])\n","    print(f'Best Accuracy in train: {k}')\n","    k = np.max(h.history[f'precision'])\n","    print(f'Best Precision in train: {k}')\n","    k = np.max(h.history[f'recall'])\n","    print(f'Best Recall in train: {k}')\n","\n","    print(\"\\nVALIDATION RESULTS:\")\n","    k = np.max(h.history[f'val_AUC_{i+1}'])\n","    print(f'Best AUC in validation: {k}')\n","    k = np.max(h.history[f'val_accuracy'])\n","    print(f'Best Accuracy in validation: {k}')\n","    k = np.max(h.history[f'val_precision'])\n","    print(f'Best Precision in validation: {k}')\n","    k = np.max(h.history[f'val_recall'])\n","    print(f'Best Recall in validation: {k}')\n","    print()\n","    print(f'{50*\"=\"}')\n","    print()\n","\n","results = np.empty((4, 5))\n","for i, h in enumerate(histories):\n","    results[0][i] = np.max(h.history[f'val_AUC_{i+1}'])\n","    results[1][i] = np.max(h.history['val_accuracy'])\n","    results[2][i] = np.max(h.history['val_precision'])\n","    results[3][i] = np.max(h.history['val_recall'])\n","\n","print(f\"Average best AUC: {np.mean(results[0])}\")\n","print(f\"standard deviation AUC: {np.std(results[0])}\\n\")\n","print(f\"Average best Accuracy: {np.mean(results[1])}\")\n","print(f\"Standard Deviation Accuracy: {np.std(results[1])}\\n\")\n","print(f\"Average best Precision: {np.mean(results[2])}\")\n","print(f\"Standard Deviation Precision: {np.std(results[2])}\\n\")\n","print(f\"Average best Recall: {np.mean(results[3])}\")\n","print(f\"Standard Deviation Recall: {np.std(results[3])}\\n\")\n"],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T17:15:38.888403Z","iopub.execute_input":"2023-08-10T17:15:38.888864Z","iopub.status.idle":"2023-08-10T17:15:38.917002Z","shell.execute_reply.started":"2023-08-10T17:15:38.888826Z","shell.execute_reply":"2023-08-10T17:15:38.916262Z"},"trusted":true,"id":"bePYyZEZpN_G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**TESTS**"],"metadata":{"id":"PQ8NKFjVpN_L"}},{"cell_type":"code","source":["training_generator = DataGenerator(list_IDs=X_train,\n","                                   labels_dir='/kaggle/input/labelsssss/labels.csv',\n","                                   dim_img=(192, 256),\n","                                   batch_size=5,\n","                                   sub_batch_size=400,\n","                                   shuffle=True,\n","                                   training=True)\n","\n","inception = get_inception_v3()\n","\n","inception.compile(loss='categorical_crossentropy',\n","                  optimizer=keras.optimizers.Adam(7e-7),\n","                  metrics=[keras.metrics.AUC(name='AUC'),\n","                           keras.metrics.Accuracy(name='accuracy'),\n","                           keras.metrics.Precision(name='precision'),\n","                           keras.metrics.Recall(name='recall')])\n","\n","\n","# Train model on dataset\n","inception.load_weights('/kaggle/working/models/cancer_auc5/') #start with best AUC in validations\n","history = inception.fit(training_generator, epochs=10)"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T17:14:59.392607Z","iopub.status.idle":"2023-08-11T17:14:59.393409Z","shell.execute_reply.started":"2023-08-11T17:14:59.393125Z","shell.execute_reply":"2023-08-11T17:14:59.393148Z"},"trusted":true,"id":"LP0QRr1OpN_Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["res = []\n","for x in X_test:\n","    x = np.load(x)\n","    x = np.array(separate_slices(x))\n","    pred = inception.predict(np.array(x), verbose=0)\n","    res.append(np.argmax(pred))\n","print(res)"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T17:34:52.743783Z","iopub.execute_input":"2023-08-11T17:34:52.744658Z","iopub.status.idle":"2023-08-11T17:35:11.753481Z","shell.execute_reply.started":"2023-08-11T17:34:52.744595Z","shell.execute_reply":"2023-08-11T17:35:11.752305Z"},"trusted":true,"id":"A3RHbNbmpN_Z","outputId":"ee1343fd-04af-4262-d7ba-1a9ee7d2d27c"},"execution_count":null,"outputs":[{"name":"stdout","text":"[0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","output_type":"stream"}]},{"cell_type":"code","source":["matrix_confusion = np.array([[0, 0, 0, 0],\n","                             [0, 0, 0, 0],\n","                             [0, 0, 0, 0],\n","                             [0, 0, 0, 0]])\n","\n","for y_pred, y_true in zip(res, y_test):\n","    matrix_confusion[y_pred][y_true] += 1\n","\n","print(matrix_confusion)"],"metadata":{"execution":{"iopub.status.busy":"2023-08-11T17:35:11.754783Z","iopub.execute_input":"2023-08-11T17:35:11.755415Z","iopub.status.idle":"2023-08-11T17:35:11.763975Z","shell.execute_reply.started":"2023-08-11T17:35:11.755377Z","shell.execute_reply":"2023-08-11T17:35:11.762817Z"},"trusted":true,"id":"_hRbvuX2pN_a","outputId":"dd6d7390-f2d0-4bc9-c720-d05374f65815"},"execution_count":null,"outputs":[{"name":"stdout","text":"[[35  5]\n [ 4  1]]\n0.8\n","output_type":"stream"}]}]}