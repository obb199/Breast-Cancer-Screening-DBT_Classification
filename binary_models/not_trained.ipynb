{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oV6XUsDY-Ed7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow import keras\n",
        "import os\n",
        "from sklearn import model_selection\n",
        "from sklearn import utils\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, RocCurveDisplay, roc_auc_score\n",
        "from scipy import ndimage\n",
        "from gc import collect\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from seaborn import heatmap"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_labels(label_file):\n",
        "    \"\"\"lê a tabela com as informações dos pacientes e retorna uma matriz com o ID e as labels\"\"\"\n",
        "    labels = pd.read_csv(label_file)\n",
        "    cancer_labels = dict()\n",
        "\n",
        "    for p in labels.index:\n",
        "        cancer_labels[labels['PatientID'][p]] = [int(labels['Normal'][p]), int(labels['Actionable'][p]), int(labels['Benign'][p]), int(labels['Cancer'][p])]\n",
        "\n",
        "    return cancer_labels"
      ],
      "metadata": {
        "id": "X0Qd5XjEOZYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = get_labels('/kaggle/input/labelsssssss/labels.csv')\n",
        "numbers_per_class = [0, 0, 0, 0]\n",
        "for i in labels:\n",
        "    numbers_per_class[np.argmax(labels[i])] += 1\n",
        "\n",
        "proportion_per_class = [round(number_of_class/sum(numbers_per_class), 2) for number_of_class in numbers_per_class]\n",
        "proportion_per_class"
      ],
      "metadata": {
        "id": "5L77dShQOaPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/kaggle/input/192x256xdepth/'\n",
        "dirs = os.listdir(path)\n",
        "\n",
        "X = [path + i for i in os.listdir(path)]\n",
        "y = [np.argmax(labels[(path+i)[-14:-4]]) for i in os.listdir(path)]"
      ],
      "metadata": {
        "id": "qqftTgmDObdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def balancing_batch(X, y, max_value):\n",
        "    numbers_per_class = sorted(Counter(y).items())\n",
        "\n",
        "    if len(numbers_per_class) == 1:\n",
        "        return X[0:1], y[0:1] #return only the first image because the batch has only one class\n",
        "\n",
        "    if numbers_per_class[0][1] > numbers_per_class[1][1]:\n",
        "        max_per_class = numbers_per_class[1][1]\n",
        "    else:\n",
        "        max_per_class = numbers_per_class[0][1]\n",
        "\n",
        "    if max_per_class > max_value//2:\n",
        "        max_per_class = max_value//2\n",
        "\n",
        "    X, y = utils.shuffle(X, y)\n",
        "    new_X, new_y = [], []\n",
        "    counter_class_zero = 0\n",
        "    counter_class_one = 0\n",
        "    for test_x, test_y in zip(X, y):\n",
        "        if test_y == 0 and counter_class_zero < max_per_class//2:\n",
        "            new_X.append(test_x)\n",
        "            new_y.append(test_y)\n",
        "            counter_class_zero += 1\n",
        "        elif test_y == 1 and counter_class_one < max_per_class//2:\n",
        "            new_X.append(test_x)\n",
        "            new_y.append(test_y)\n",
        "            counter_class_one += 1\n",
        "\n",
        "    return np.array(new_X, dtype='float16'), np.array(new_y, dtype='float16')"
      ],
      "metadata": {
        "id": "qVXaYu5sOcpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def separate_slices(img):\n",
        "    'function to separate 2d images of 3d original image'\n",
        "    slices = []\n",
        "\n",
        "    for i in range(img.shape[-2]):\n",
        "        slices.append(np.array(img[:, :, i]))\n",
        "\n",
        "    slices.append(np.mean(img, axis=-2)) #including mean of slices\n",
        "\n",
        "    return slices"
      ],
      "metadata": {
        "id": "mYqoB7AHOd3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, stratify=y,random_state=42, train_size=0.8)"
      ],
      "metadata": {
        "id": "0eSBxVVHOfUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, objective, list_IDs, labels_dir, batch_size, sub_batch_size, dim_img, training, shuffle=True):\n",
        "        self.objective = objective # list representing one hot encoding for choice label ([1, 0, 0, 0] for normal, [0, 0, 0, 1] for cancer ..)\n",
        "        self.list_IDs = list_IDs # array of strings with original images name with directory\n",
        "        self.labels = self.__get_labels(labels_dir) #dict with labels of all images\n",
        "        self.batch_size = batch_size #3d-images per batch\n",
        "        self.sub_batch_size = sub_batch_size #quantity of sub-images per batch will be choose to train\n",
        "        self.dim_img = dim_img # tuple with width and height of image like (192, 256)\n",
        "        self.training = training # true if generator is for training, false if generator is for validation\n",
        "        self.shuffle = shuffle # true or false to shuffle data after any epochs\n",
        "        self.on_epoch_end() # call of the function\n",
        "\n",
        "\n",
        "    def __get_labels(self, label_file):\n",
        "        'take the dict with labels of images'\n",
        "        labels = pd.read_csv(label_file)\n",
        "        cancer_labels = dict()\n",
        "\n",
        "        for p in labels.index:\n",
        "            cancer_labels[labels['PatientID'][p]] = [int(labels['Normal'][p]), int(labels['Actionable'][p]), int(labels['Benign'][p]), int(labels['Cancer'][p])]\n",
        "\n",
        "        return cancer_labels\n",
        "\n",
        "    def __data_augmentation(self, x):\n",
        "        'generate variations of images'\n",
        "        new_images = []\n",
        "        x = x.astype('float16')\n",
        "        new_images.append(x)\n",
        "\n",
        "        x = cv2.flip(x.astype('float32'), 1).astype('float16')\n",
        "\n",
        "        new_images.append(np.expand_dims(x, -1))\n",
        "\n",
        "        return utils.shuffle(new_images)\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "        if self.training:\n",
        "            X, y = balancing_batch(X, y, self.sub_batch_size)\n",
        "            return np.array(X[0:self.sub_batch_size], dtype='float16'), np.array(y[0:self.sub_batch_size], dtype='uint8')\n",
        "\n",
        "        return np.array(X), np.array(y)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        'Generates data containing batch_size samples'\n",
        "        X = []\n",
        "        y = []\n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            # Store sample\n",
        "            prev_len_X = len(X)\n",
        "            full_image = np.load(ID)\n",
        "            new_images = separate_slices(full_image)\n",
        "            if self.training:\n",
        "                for img in new_images:\n",
        "                    X += self.__data_augmentation(img)\n",
        "            else:\n",
        "                X = np.array(new_images, dtype='float16')\n",
        "\n",
        "            #adding new data labels for y array\n",
        "            for _ in range(len(X) - prev_len_X):\n",
        "                if self.labels[ID[-14:-4]] == self.objective: #'-14:-4 represent a part of string with name of original image that slices was taken'\n",
        "                    y.append(1)\n",
        "                else:\n",
        "                    y.append(0)\n",
        "\n",
        "        X, y = utils.shuffle(X, y)\n",
        "        return X, y"
      ],
      "metadata": {
        "id": "nImg2VzGOgXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvLayer(keras.layers.Layer):\n",
        "    def __init__(self, filters, kernel_x, kernel_y, activation='relu', strides=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = keras.layers.Conv2D(filters=filters, kernel_size=(1,1), padding='same')\n",
        "        self.conv2 = keras.layers.Conv2D(filters=filters, kernel_size=(kernel_x, kernel_y), padding='same', strides=strides,)\n",
        "        self.bn    = keras.layers.BatchNormalization()\n",
        "        self.activation = keras.layers.get_activation(activation)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "class DenseBlock(keras.layers.Layer):\n",
        "    def __init__(self, filters, strides=1, activation='relu', **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.activation = keras.activations.get(activation)\n",
        "        self.conv_layers = [ConvLayer(filters, 2, 4) for _ in range(16)]\n",
        "\n",
        "    actual_input = x\n",
        "    def call(self, x):\n",
        "      for conv_layer in self.conv_layers:\n",
        "        output = conv_layer(atual_input)\n",
        "        actual_input = tf.concat([actual_input, output], axis=-1)\n",
        "      return output\n",
        "\n",
        "class DenseNET(keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv   = keras.layers.Conv2D(filters=16, kernel_size=(7, 9), strides=2, activation='relu', padding='same')\n",
        "        self.bn1    = keras.layers.BatchNormalization()\n",
        "        self.block1 = DenseBlock(32)\n",
        "        self.conv1  = ConvLayer(64, 1, 1)\n",
        "        self.pool1  = keras.layers.MaxPooling2D(kernel=(2,2), strides=2)\n",
        "        self.block2 = DenseBlock(64)\n",
        "        self.conv2  = ConvLayer(64, 1, 1)\n",
        "        self.pool2  = keras.layers.MaxPooling2D(kernel=(2,2), strides=2)\n",
        "        self.block3 = DenseBlock(128)\n",
        "        self.pool3  = keras.layers.GlobalAveragePooling2D()\n",
        "        self.dense = keras.layers.Dense(units=1, activation='sigmoid')\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.block1(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.pool3(x)\n",
        "        x = self.dense(x)\n",
        "\n",
        "      return x"
      ],
      "metadata": {
        "id": "4D2eaUit-IR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NORMAL"
      ],
      "metadata": {
        "id": "nRwo_8RTOl58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_callback_auc1 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/normal_auc1/',\n",
        "                                                             save_weights_only=True,\n",
        "                                                             monitor='val_AUC_1',\n",
        "                                                             mode='max',\n",
        "                                                             save_best_only=True)\n",
        "checkpoint_callback_auc2 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/normal_auc2/',\n",
        "                                                             save_weights_only=True,\n",
        "                                                             monitor='val_AUC_2',\n",
        "                                                             mode='max',\n",
        "                                                             save_best_only=True)\n",
        "checkpoint_callback_auc3 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/normal_auc3/',\n",
        "                                                             save_weights_only=True,\n",
        "                                                             monitor='val_AUC_3',\n",
        "                                                             mode='max',\n",
        "                                                             save_best_only=True)\n",
        "checkpoint_callback_auc4 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/normal_auc4/',\n",
        "                                                             save_weights_only=True,\n",
        "                                                             monitor='val_AUC_4',\n",
        "                                                             mode='max',\n",
        "                                                             save_best_only=True)\n",
        "checkpoint_callback_auc5 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/normal_auc5/',\n",
        "                                                             save_weights_only=True,\n",
        "                                                             monitor='val_AUC_5',\n",
        "                                                             mode='max',\n",
        "                                                             save_best_only=True)\n",
        "\n",
        "callbacks_list = [checkpoint_callback_auc1,\n",
        "                  checkpoint_callback_auc2,\n",
        "                  checkpoint_callback_auc3,\n",
        "                  checkpoint_callback_auc4,\n",
        "                  checkpoint_callback_auc5]\n",
        "\n",
        "def lr_scheduler(epoch, lr):\n",
        "    return lr*0.9\n",
        "\n",
        "lr_decay_function = keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=0)"
      ],
      "metadata": {
        "id": "y5WaY1ncOnjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "histories = []\n",
        "n_splits = 5\n",
        "skf = model_selection.StratifiedShuffleSplit(n_splits=n_splits, random_state=314, train_size=0.85)\n",
        "for number_of_split, data in enumerate(skf.split(X_train, y_train)):\n",
        "    print(f'SPLIT {number_of_split+1}/{n_splits}:')\n",
        "    train = [path + dirs[i] for i in data[0]]\n",
        "    val = [path + dirs[j] for j in data[1]]\n",
        "\n",
        "    # Generators\n",
        "    training_generator = DataGenerator(objective=[1, 0, 0, 0],\n",
        "                                       list_IDs=train,\n",
        "                                       labels_dir='/kaggle/input/labelsssssss/labels.csv',\n",
        "                                       dim_img=(192, 256),\n",
        "                                       batch_size=5,\n",
        "                                       sub_batch_size=400,\n",
        "                                       shuffle=True,\n",
        "                                       training=True)\n",
        "\n",
        "    validation_generator = DataGenerator(objective=[1, 0, 0, 0],\n",
        "                                         list_IDs=val,\n",
        "                                         labels_dir='/kaggle/input/labelsssssss/labels.csv',\n",
        "                                         dim_img=(192, 256),\n",
        "                                         batch_size=1,\n",
        "                                         sub_batch_size='IGNORED', #this argument will be ignored because training is false.\n",
        "                                         shuffle=True,\n",
        "                                         training=False)\n",
        "\n",
        "    densenet = DenseNET()\n",
        "\n",
        "    densenet.compile(loss='binary_crossentropy',\n",
        "                     optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "                     metrics=[keras.metrics.AUC(name=f'AUC_{number_of_split+1}'),\n",
        "                              keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "                              keras.metrics.Precision(name='precision'),\n",
        "                              keras.metrics.Recall(name='recall')])\n",
        "\n",
        "\n",
        "    # Train model on dataset\n",
        "    histories.append(densenet.fit(training_generator,\n",
        "                                   validation_data=validation_generator,\n",
        "                                   epochs=35,\n",
        "                                   use_multiprocessing=True,\n",
        "                                   workers=1,\n",
        "                                   callbacks=[callbacks_list[number_of_split], lr_decay_function]))\n",
        "    print('\\n')\n",
        "    collect()"
      ],
      "metadata": {
        "id": "uaI56hYwOnvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(25, 50))\n",
        "plt.subplot(4, 2, 1)\n",
        "for i, h in enumerate(histories):\n",
        "    plt.plot(list(range(1, 36)), h.history['loss'], marker='o')\n",
        "    plt.title('DenseNET Loss evolution - Training: Normal vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('Loss on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n",
        "\n",
        "plt.subplot(4, 2, 2)\n",
        "for i, h in enumerate(histories):\n",
        "    plt.plot(list(range(1, 36)), h.history['val_loss'], marker='o')\n",
        "    plt.title('DenseNET4 Loss evolution - Validations: Normal vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('Loss on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n",
        "\n",
        "plt.subplot(4, 2, 3)\n",
        "for i, h in enumerate(histories):\n",
        "    plt.plot(list(range(1, 36)), h.history['accuracy'], marker='o')\n",
        "    plt.title('DenseNET Accuracy evolution - Training: Normal vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('Accuracy on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n",
        "\n",
        "plt.subplot(4, 2, 4)\n",
        "for i, h in enumerate(histories):\n",
        "    plt.plot(list(range(1, 36)), h.history['val_accuracy'], marker='o')\n",
        "    plt.title('DenseNET Accuracy evolution - Validations: Normal vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('Accuracy on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n",
        "\n",
        "plt.subplot(4, 2, 5)\n",
        "for i, h in enumerate(histories):\n",
        "    plt.plot(list(range(1, 36)), h.history['recall'], marker='o')\n",
        "    plt.title('DenseNET Recall evolution - Training: Normal vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('Recall on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n",
        "\n",
        "plt.subplot(4, 2, 6)\n",
        "for i, h in enumerate(histories):\n",
        "    plt.plot(list(range(1, 36)), h.history['val_recall'], marker='o')\n",
        "    plt.title('DenseNET Recall evolution - Validations: Normal vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('Recall on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n",
        "\n",
        "plt.subplot(4, 2, 7)\n",
        "for i, h in enumerate(histories):\n",
        "    key_auc = f\"AUC_{i+1}\"\n",
        "    plt.plot(list(range(1, 36)), h.history[key_auc], marker='o')\n",
        "    plt.title('DenseNET AUC evolution - Training: Normal vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('AUC on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n",
        "\n",
        "plt.subplot(4, 2, 8)\n",
        "for i, h in enumerate(histories):\n",
        "    key_auc_val = f\"val_AUC_{i+1}\"\n",
        "    plt.plot(list(range(1, 36)), h.history[key_auc_val], marker='o')\n",
        "    plt.title('DenseNET AUC evolution - Validations: Normal vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('AUC on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])"
      ],
      "metadata": {
        "id": "SuzF7Ep6Onyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Best results in validations for any k-fold: ')\n",
        "for i, h in enumerate(histories):\n",
        "    print(f'K-FOLD {i+1}:')\n",
        "    print(\"TRAINING RESULTS:\")\n",
        "    k = np.max(h.history[f'AUC_{i+1}'])\n",
        "    print(f'Best AUC in train: {k}')\n",
        "    k = np.max(h.history[f'accuracy'])\n",
        "    print(f'Best Accuracy in train: {k}')\n",
        "    k = np.max(h.history[f'precision'])\n",
        "    print(f'Best Precision in train: {k}')\n",
        "    k = np.max(h.history[f'recall'])\n",
        "    print(f'Best Recall in train: {k}')\n",
        "\n",
        "    print(\"\\nVALIDATION RESULTS:\")\n",
        "    k = np.max(h.history[f'val_AUC_{i+1}'])\n",
        "    print(f'Best AUC in validation: {k}')\n",
        "    k = np.max(h.history[f'val_accuracy'])\n",
        "    print(f'Best Accuracy in validation: {k}')\n",
        "    k = np.max(h.history[f'val_precision'])\n",
        "    print(f'Best Precision in validation: {k}')\n",
        "    k = np.max(h.history[f'val_recall'])\n",
        "    print(f'Best Recall in validation: {k}')\n",
        "    print()\n",
        "    print(f'{50*\"=\"}')\n",
        "    print()\n",
        "\n",
        "results = np.empty((4, 5))\n",
        "for i, h in enumerate(histories):\n",
        "    results[0][i] = np.max(h.history[f'val_AUC_{i+1}'])\n",
        "    results[1][i] = np.max(h.history['val_accuracy'])\n",
        "    results[2][i] = np.max(h.history['val_precision'])\n",
        "    results[3][i] = np.max(h.history['val_recall'])\n",
        "\n",
        "print(f\"Average best AUC: {np.mean(results[0])}\")\n",
        "print(f\"standard deviation AUC: {np.std(results[0])}\\n\")\n",
        "print(f\"Average best Accuracy: {np.mean(results[1])}\")\n",
        "print(f\"Standard Deviation Accuracy: {np.std(results[1])}\\n\")\n",
        "print(f\"Average best Precision: {np.mean(results[2])}\")\n",
        "print(f\"Standard Deviation Precision: {np.std(results[2])}\\n\")\n",
        "print(f\"Average best Recall: {np.mean(results[3])}\")\n",
        "print(f\"Standard Deviation Recall: {np.std(results[3])}\\n\")\n"
      ],
      "metadata": {
        "id": "UfwvorpKOs84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ACTIONABLE"
      ],
      "metadata": {
        "id": "PdsXJVPVOvVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_callback_auc1 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/actionable_auc1/',\n",
        "                                                             save_weights_only=True,\n",
        "                                                             monitor='val_AUC_1',\n",
        "                                                             mode='max',\n",
        "                                                             save_best_only=True)\n",
        "checkpoint_callback_auc2 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/actionable_auc2/',\n",
        "                                                             save_weights_only=True,\n",
        "                                                             monitor='val_AUC_2',\n",
        "                                                             mode='max',\n",
        "                                                             save_best_only=True)\n",
        "checkpoint_callback_auc3 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/actionable_auc3/',\n",
        "                                                             save_weights_only=True,\n",
        "                                                             monitor='val_AUC_3',\n",
        "                                                             mode='max',\n",
        "                                                             save_best_only=True)\n",
        "checkpoint_callback_auc4 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/actionable_auc4/',\n",
        "                                                             save_weights_only=True,\n",
        "                                                             monitor='val_AUC_4',\n",
        "                                                             mode='max',\n",
        "                                                             save_best_only=True)\n",
        "checkpoint_callback_auc5 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/actionable_auc5/',\n",
        "                                                             save_weights_only=True,\n",
        "                                                             monitor='val_AUC_5',\n",
        "                                                             mode='max',\n",
        "                                                             save_best_only=True)\n",
        "\n",
        "callbacks_list = [checkpoint_callback_auc1,\n",
        "                  checkpoint_callback_auc2,\n",
        "                  checkpoint_callback_auc3,\n",
        "                  checkpoint_callback_auc4,\n",
        "                  checkpoint_callback_auc5]\n",
        "\n",
        "def lr_scheduler(epoch, lr):\n",
        "    return lr*0.9\n",
        "\n",
        "lr_decay_function = keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=0)"
      ],
      "metadata": {
        "id": "nnfMU8GTOuJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "histories = []\n",
        "n_splits = 5\n",
        "skf = model_selection.StratifiedShuffleSplit(n_splits=n_splits, random_state=314, train_size=0.85)\n",
        "for number_of_split, data in enumerate(skf.split(X_train, y_train)):\n",
        "    print(f'SPLIT {number_of_split+1}/{n_splits}:')\n",
        "    train = [path + dirs[i] for i in data[0]]\n",
        "    val = [path + dirs[j] for j in data[1]]\n",
        "\n",
        "    # Generators\n",
        "    training_generator = DataGenerator(objective=[0, 1, 0, 0],\n",
        "                                       list_IDs=train,\n",
        "                                       labels_dir='/kaggle/input/labelsssssss/labels.csv',\n",
        "                                       dim_img=(192, 256),\n",
        "                                       batch_size=5,\n",
        "                                       sub_batch_size=400,\n",
        "                                       shuffle=True,\n",
        "                                       training=True)\n",
        "\n",
        "    validation_generator = DataGenerator(objective=[0, 1, 0, 0],\n",
        "                                         list_IDs=val,\n",
        "                                         labels_dir='/kaggle/input/labelsssssss/labels.csv',\n",
        "                                         dim_img=(192, 256),\n",
        "                                         batch_size=1,\n",
        "                                         sub_batch_size='IGNORED', #this argument will be ignored because training is false.\n",
        "                                         shuffle=True,\n",
        "                                         training=False)\n",
        "\n",
        "    densenet = DenseNET()\n",
        "\n",
        "    densenet.compile(loss='binary_crossentropy',\n",
        "                     optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "                     metrics=[keras.metrics.AUC(name=f'AUC_{number_of_split+1}'),\n",
        "                              keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "                              keras.metrics.Precision(name='precision'),\n",
        "                              keras.metrics.Recall(name='recall')])\n",
        "\n",
        "\n",
        "    # Train model on dataset\n",
        "    histories.append(densenet.fit(training_generator,\n",
        "                                   validation_data=validation_generator,\n",
        "                                   epochs=35,\n",
        "                                   use_multiprocessing=True,\n",
        "                                   workers=1,\n",
        "                                   callbacks=[callbacks_list[number_of_split], lr_decay_function]))\n",
        "    print('\\n')\n",
        "    collect()"
      ],
      "metadata": {
        "id": "mM_HM5mlOx4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(25, 50))\n",
        "plt.subplot(4, 2, 1)\n",
        "for i, h in enumerate(histories):\n",
        "    plt.plot(list(range(1, 36)), h.history['loss'], marker='o')\n",
        "    plt.title('DenseNET Loss evolution - Training: Actionable vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('Loss on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n",
        "\n",
        "plt.subplot(4, 2, 2)\n",
        "for i, h in enumerate(histories):\n",
        "    plt.plot(list(range(1, 36)), h.history['val_loss'], marker='o')\n",
        "    plt.title('DenseNET Loss evolution - Validations: Actionable vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('Loss on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n",
        "\n",
        "plt.subplot(4, 2, 3)\n",
        "for i, h in enumerate(histories):\n",
        "    plt.plot(list(range(1, 36)), h.history['accuracy'], marker='o')\n",
        "    plt.title('DenseNET Accuracy evolution - Training: Actionable vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('Accuracy on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n",
        "\n",
        "plt.subplot(4, 2, 4)\n",
        "for i, h in enumerate(histories):\n",
        "    plt.plot(list(range(1, 36)), h.history['val_accuracy'], marker='o')\n",
        "    plt.title('DenseNET Accuracy evolution - Validations: Actionable vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('Accuracy on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n",
        "\n",
        "plt.subplot(4, 2, 5)\n",
        "for i, h in enumerate(histories):\n",
        "    plt.plot(list(range(1, 36)), h.history['recall'], marker='o')\n",
        "    plt.title('DenseNET Recall evolution - Training: Actionable vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('Recall on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n",
        "\n",
        "plt.subplot(4, 2, 6)\n",
        "for i, h in enumerate(histories):\n",
        "    plt.plot(list(range(1, 36)), h.history['val_recall'], marker='o')\n",
        "    plt.title('DenseNET Recall evolution - Validations: Actionable vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('Recall on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n",
        "\n",
        "plt.subplot(4, 2, 7)\n",
        "for i, h in enumerate(histories):\n",
        "    key_auc = f\"AUC_{i+1}\"\n",
        "    plt.plot(list(range(1, 36)), h.history[key_auc], marker='o')\n",
        "    plt.title('DenseNET AUC evolution - Training: Actionable vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('AUC on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n",
        "\n",
        "plt.subplot(4, 2, 8)\n",
        "for i, h in enumerate(histories):\n",
        "    key_auc_val = f\"val_AUC_{i+1}\"\n",
        "    plt.plot(list(range(1, 36)), h.history[key_auc_val], marker='o')\n",
        "    plt.title('DenseNET AUC evolution - Validations: Actionable vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('AUC on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])"
      ],
      "metadata": {
        "id": "UGn-k7y2O1Lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Best results in validations for any k-fold: ')\n",
        "for i, h in enumerate(histories):\n",
        "    print(f'K-FOLD {i+1}:')\n",
        "    print(\"TRAINING RESULTS:\")\n",
        "    k = np.max(h.history[f'AUC_{i+1}'])\n",
        "    print(f'Best AUC in train: {k}')\n",
        "    k = np.max(h.history[f'accuracy'])\n",
        "    print(f'Best Accuracy in train: {k}')\n",
        "    k = np.max(h.history[f'precision'])\n",
        "    print(f'Best Precision in train: {k}')\n",
        "    k = np.max(h.history[f'recall'])\n",
        "    print(f'Best Recall in train: {k}')\n",
        "\n",
        "    print(\"\\nVALIDATION RESULTS:\")\n",
        "    k = np.max(h.history[f'val_AUC_{i+1}'])\n",
        "    print(f'Best AUC in validation: {k}')\n",
        "    k = np.max(h.history[f'val_accuracy'])\n",
        "    print(f'Best Accuracy in validation: {k}')\n",
        "    k = np.max(h.history[f'val_precision'])\n",
        "    print(f'Best Precision in validation: {k}')\n",
        "    k = np.max(h.history[f'val_recall'])\n",
        "    print(f'Best Recall in validation: {k}')\n",
        "    print()\n",
        "    print(f'{50*\"=\"}')\n",
        "    print()\n",
        "\n",
        "results = np.empty((4, 5))\n",
        "for i, h in enumerate(histories):\n",
        "    results[0][i] = np.max(h.history[f'val_AUC_{i+1}'])\n",
        "    results[1][i] = np.max(h.history['val_accuracy'])\n",
        "    results[2][i] = np.max(h.history['val_precision'])\n",
        "    results[3][i] = np.max(h.history['val_recall'])\n",
        "\n",
        "print(f\"Average best AUC: {np.mean(results[0])}\")\n",
        "print(f\"standard deviation AUC: {np.std(results[0])}\\n\")\n",
        "print(f\"Average best Accuracy: {np.mean(results[1])}\")\n",
        "print(f\"Standard Deviation Accuracy: {np.std(results[1])}\\n\")\n",
        "print(f\"Average best Precision: {np.mean(results[2])}\")\n",
        "print(f\"Standard Deviation Precision: {np.std(results[2])}\\n\")\n",
        "print(f\"Average best Recall: {np.mean(results[3])}\")\n",
        "print(f\"Standard Deviation Recall: {np.std(results[3])}\\n\")\n"
      ],
      "metadata": {
        "id": "0Vo5A4r8O3sP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BENIGN"
      ],
      "metadata": {
        "id": "rFm2t3MLO4w2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_callback_auc1 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/benign_auc1/',\n",
        "                                                             save_weights_only=True,\n",
        "                                                             monitor='val_AUC_1',\n",
        "                                                             mode='max',\n",
        "                                                             save_best_only=True)\n",
        "checkpoint_callback_auc2 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/benign_auc2/',\n",
        "                                                             save_weights_only=True,\n",
        "                                                             monitor='val_AUC_2',\n",
        "                                                             mode='max',\n",
        "                                                             save_best_only=True)\n",
        "checkpoint_callback_auc3 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/benign_auc3/',\n",
        "                                                             save_weights_only=True,\n",
        "                                                             monitor='val_AUC_3',\n",
        "                                                             mode='max',\n",
        "                                                             save_best_only=True)\n",
        "checkpoint_callback_auc4 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/benign_auc4/',\n",
        "                                                             save_weights_only=True,\n",
        "                                                             monitor='val_AUC_4',\n",
        "                                                             mode='max',\n",
        "                                                             save_best_only=True)\n",
        "checkpoint_callback_auc5 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/benign_auc5/',\n",
        "                                                             save_weights_only=True,\n",
        "                                                             monitor='val_AUC_5',\n",
        "                                                             mode='max',\n",
        "                                                             save_best_only=True)\n",
        "\n",
        "callbacks_list = [checkpoint_callback_auc1,\n",
        "                  checkpoint_callback_auc2,\n",
        "                  checkpoint_callback_auc3,\n",
        "                  checkpoint_callback_auc4,\n",
        "                  checkpoint_callback_auc5]\n",
        "\n",
        "def lr_scheduler(epoch, lr):\n",
        "    return lr*0.9\n",
        "\n",
        "lr_decay_function = keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=0)"
      ],
      "metadata": {
        "id": "PXU_iLYHO5uG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "histories = []\n",
        "n_splits = 5\n",
        "skf = model_selection.StratifiedShuffleSplit(n_splits=n_splits, random_state=314, train_size=0.85)\n",
        "for number_of_split, data in enumerate(skf.split(X_train, y_train)):\n",
        "    print(f'SPLIT {number_of_split+1}/{n_splits}:')\n",
        "    train = [path + dirs[i] for i in data[0]]\n",
        "    val = [path + dirs[j] for j in data[1]]\n",
        "\n",
        "    # Generators\n",
        "    training_generator = DataGenerator(objective=[0, 0, 1, 0],\n",
        "                                       list_IDs=train,\n",
        "                                       labels_dir='/kaggle/input/labelsssssss/labels.csv',\n",
        "                                       dim_img=(192, 256),\n",
        "                                       batch_size=5,\n",
        "                                       sub_batch_size=400,\n",
        "                                       shuffle=True,\n",
        "                                       training=True)\n",
        "\n",
        "    validation_generator = DataGenerator(objective=[0, 0, 1, 0],\n",
        "                                         list_IDs=val,\n",
        "                                         labels_dir='/kaggle/input/labelsssssss/labels.csv',\n",
        "                                         dim_img=(192, 256),\n",
        "                                         batch_size=1,\n",
        "                                         sub_batch_size='IGNORED', #this argument will be ignored because training is false.\n",
        "                                         shuffle=True,\n",
        "                                         training=False)\n",
        "\n",
        "    densenet = DenseNET()\n",
        "\n",
        "    densenet.compile(loss='binary_crossentropy',\n",
        "                     optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "                     metrics=[keras.metrics.AUC(name=f'AUC_{number_of_split+1}'),\n",
        "                              keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "                              keras.metrics.Precision(name='precision'),\n",
        "                              keras.metrics.Recall(name='recall')])\n",
        "\n",
        "\n",
        "    # Train model on dataset\n",
        "    histories.append(densenet.fit(training_generator,\n",
        "                                   validation_data=validation_generator,\n",
        "                                   epochs=35,\n",
        "                                   use_multiprocessing=True,\n",
        "                                   workers=1,\n",
        "                                   callbacks=[callbacks_list[number_of_split], lr_decay_function]))\n",
        "    print('\\n')\n",
        "    collect()"
      ],
      "metadata": {
        "id": "eOi9-XlgO7Xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(25, 50))\n",
        "plt.subplot(4, 2, 1)\n",
        "for i, h in enumerate(histories):\n",
        "    plt.plot(list(range(1, 36)), h.history['loss'], marker='o')\n",
        "    plt.title('DenseNET Loss evolution - Training: Benign vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('Loss on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n",
        "\n",
        "plt.subplot(4, 2, 2)\n",
        "for i, h in enumerate(histories):\n",
        "    plt.plot(list(range(1, 36)), h.history['val_loss'], marker='o')\n",
        "    plt.title('DenseNET Loss evolution - Validations: Benign vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('Loss on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n",
        "\n",
        "plt.subplot(4, 2, 3)\n",
        "for i, h in enumerate(histories):\n",
        "    plt.plot(list(range(1, 36)), h.history['accuracy'], marker='o')\n",
        "    plt.title('DenseNET Accuracy evolution - Training: Benign vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('Accuracy on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n",
        "\n",
        "plt.subplot(4, 2, 4)\n",
        "for i, h in enumerate(histories):\n",
        "    plt.plot(list(range(1, 36)), h.history['val_accuracy'], marker='o')\n",
        "    plt.title('DenseNET Accuracy evolution - Validations: Benign vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('Accuracy on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n",
        "\n",
        "plt.subplot(4, 2, 5)\n",
        "for i, h in enumerate(histories):\n",
        "    plt.plot(list(range(1, 36)), h.history['recall'], marker='o')\n",
        "    plt.title('DenseNET Recall evolution - Training: Benign vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('Recall on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n",
        "\n",
        "plt.subplot(4, 2, 6)\n",
        "for i, h in enumerate(histories):\n",
        "    plt.plot(list(range(1, 36)), h.history['val_recall'], marker='o')\n",
        "    plt.title('DenseNET Recall evolution - Validations: Benign vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('Recall on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n",
        "\n",
        "plt.subplot(4, 2, 7)\n",
        "for i, h in enumerate(histories):\n",
        "    key_auc = f\"AUC_{i+1}\"\n",
        "    plt.plot(list(range(1, 36)), h.history[key_auc], marker='o')\n",
        "    plt.title('DenseNET AUC evolution - Training: Benign vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('AUC on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n",
        "\n",
        "plt.subplot(4, 2, 8)\n",
        "for i, h in enumerate(histories):\n",
        "    key_auc_val = f\"val_AUC_{i+1}\"\n",
        "    plt.plot(list(range(1, 36)), h.history[key_auc_val], marker='o')\n",
        "    plt.title('DenseNET AUC evolution - Validations: Benign vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('AUC on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])"
      ],
      "metadata": {
        "id": "PGL9thPPO7aE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Best results in validations for any k-fold: ')\n",
        "for i, h in enumerate(histories):\n",
        "    print(f'K-FOLD {i+1}:')\n",
        "    print(\"TRAINING RESULTS:\")\n",
        "    k = np.max(h.history[f'AUC_{i+1}'])\n",
        "    print(f'Best AUC in train: {k}')\n",
        "    k = np.max(h.history[f'accuracy'])\n",
        "    print(f'Best Accuracy in train: {k}')\n",
        "    k = np.max(h.history[f'precision'])\n",
        "    print(f'Best Precision in train: {k}')\n",
        "    k = np.max(h.history[f'recall'])\n",
        "    print(f'Best Recall in train: {k}')\n",
        "\n",
        "    print(\"\\nVALIDATION RESULTS:\")\n",
        "    k = np.max(h.history[f'val_AUC_{i+1}'])\n",
        "    print(f'Best AUC in validation: {k}')\n",
        "    k = np.max(h.history[f'val_accuracy'])\n",
        "    print(f'Best Accuracy in validation: {k}')\n",
        "    k = np.max(h.history[f'val_precision'])\n",
        "    print(f'Best Precision in validation: {k}')\n",
        "    k = np.max(h.history[f'val_recall'])\n",
        "    print(f'Best Recall in validation: {k}')\n",
        "    print()\n",
        "    print(f'{50*\"=\"}')\n",
        "    print()\n",
        "\n",
        "results = np.empty((4, 5))\n",
        "for i, h in enumerate(histories):\n",
        "    results[0][i] = np.max(h.history[f'val_AUC_{i+1}'])\n",
        "    results[1][i] = np.max(h.history['val_accuracy'])\n",
        "    results[2][i] = np.max(h.history['val_precision'])\n",
        "    results[3][i] = np.max(h.history['val_recall'])\n",
        "\n",
        "print(f\"Average best AUC: {np.mean(results[0])}\")\n",
        "print(f\"standard deviation AUC: {np.std(results[0])}\\n\")\n",
        "print(f\"Average best Accuracy: {np.mean(results[1])}\")\n",
        "print(f\"Standard Deviation Accuracy: {np.std(results[1])}\\n\")\n",
        "print(f\"Average best Precision: {np.mean(results[2])}\")\n",
        "print(f\"Standard Deviation Precision: {np.std(results[2])}\\n\")\n",
        "print(f\"Average best Recall: {np.mean(results[3])}\")\n",
        "print(f\"Standard Deviation Recall: {np.std(results[3])}\\n\")"
      ],
      "metadata": {
        "id": "hnu9cIUhO7lX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CANCER"
      ],
      "metadata": {
        "id": "rgnNQZ7QPAtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_callback_auc1 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/cancer_auc1/',\n",
        "                                                             save_weights_only=True,\n",
        "                                                             monitor='val_AUC_1',\n",
        "                                                             mode='max',\n",
        "                                                             save_best_only=True)\n",
        "checkpoint_callback_auc2 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/cancer_auc2/',\n",
        "                                                             save_weights_only=True,\n",
        "                                                             monitor='val_AUC_2',\n",
        "                                                             mode='max',\n",
        "                                                             save_best_only=True)\n",
        "checkpoint_callback_auc3 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/cancer_auc3/',\n",
        "                                                             save_weights_only=True,\n",
        "                                                             monitor='val_AUC_3',\n",
        "                                                             mode='max',\n",
        "                                                             save_best_only=True)\n",
        "checkpoint_callback_auc4 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/cancer_auc4/',\n",
        "                                                             save_weights_only=True,\n",
        "                                                             monitor='val_AUC_4',\n",
        "                                                             mode='max',\n",
        "                                                             save_best_only=True)\n",
        "checkpoint_callback_auc5 = tf.keras.callbacks.ModelCheckpoint(filepath='./models/cancer_auc5/',\n",
        "                                                             save_weights_only=True,\n",
        "                                                             monitor='val_AUC_5',\n",
        "                                                             mode='max',\n",
        "                                                             save_best_only=True)\n",
        "\n",
        "callbacks_list = [checkpoint_callback_auc1,\n",
        "                  checkpoint_callback_auc2,\n",
        "                  checkpoint_callback_auc3,\n",
        "                  checkpoint_callback_auc4,\n",
        "                  checkpoint_callback_auc5]\n",
        "\n",
        "def lr_scheduler(epoch, lr):\n",
        "    return lr*0.9\n",
        "\n",
        "lr_decay_function = keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=0)"
      ],
      "metadata": {
        "id": "tZnfQzo1O_f5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "histories = []\n",
        "n_splits = 5\n",
        "skf = model_selection.StratifiedShuffleSplit(n_splits=n_splits, random_state=314, train_size=0.85)\n",
        "for number_of_split, data in enumerate(skf.split(X_train, y_train)):\n",
        "    print(f'SPLIT {number_of_split+1}/{n_splits}:')\n",
        "    train = [path + dirs[i] for i in data[0]]\n",
        "    val = [path + dirs[j] for j in data[1]]\n",
        "\n",
        "    # Generators\n",
        "    training_generator = DataGenerator(objective=[0, 0, 0, 1],\n",
        "                                       list_IDs=train,\n",
        "                                       labels_dir='/kaggle/input/labelsssssss/labels.csv',\n",
        "                                       dim_img=(192, 256),\n",
        "                                       batch_size=5,\n",
        "                                       sub_batch_size=400,\n",
        "                                       shuffle=True,\n",
        "                                       training=True)\n",
        "\n",
        "    validation_generator = DataGenerator(objective=[0, 0, 0, 1],\n",
        "                                         list_IDs=val,\n",
        "                                         labels_dir='/kaggle/input/labelsssssss/labels.csv',\n",
        "                                         dim_img=(192, 256),\n",
        "                                         batch_size=1,\n",
        "                                         sub_batch_size='IGNORED', #this argument will be ignored because training is false.\n",
        "                                         shuffle=True,\n",
        "                                         training=False)\n",
        "\n",
        "    densenet = DenseNET()\n",
        "\n",
        "    densenet.compile(loss='binary_crossentropy',\n",
        "                     optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "                     metrics=[keras.metrics.AUC(name=f'AUC_{number_of_split+1}'),\n",
        "                              keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "                              keras.metrics.Precision(name='precision'),\n",
        "                              keras.metrics.Recall(name='recall')])\n",
        "\n",
        "\n",
        "    # Train model on dataset\n",
        "    histories.append(densenet.fit(training_generator,\n",
        "                                   validation_data=validation_generator,\n",
        "                                   epochs=35,\n",
        "                                   use_multiprocessing=True,\n",
        "                                   workers=1,\n",
        "                                   callbacks=[callbacks_list[number_of_split], lr_decay_function]))\n",
        "    print('\\n')\n",
        "    collect()"
      ],
      "metadata": {
        "id": "q-Ltzvo9PCyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(25, 50))\n",
        "plt.subplot(4, 2, 1)\n",
        "for i, h in enumerate(histories):\n",
        "    plt.plot(list(range(1, 36)), h.history['loss'], marker='o')\n",
        "    plt.title('DenseNET Loss evolution - Training: Cancer vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('Loss on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n",
        "\n",
        "plt.subplot(4, 2, 2)\n",
        "for i, h in enumerate(histories):\n",
        "    plt.plot(list(range(1, 36)), h.history['val_loss'], marker='o')\n",
        "    plt.title('DenseNET Loss evolution - Validations: Cancer vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('Loss on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n",
        "\n",
        "plt.subplot(4, 2, 3)\n",
        "for i, h in enumerate(histories):\n",
        "    plt.plot(list(range(1, 36)), h.history['accuracy'], marker='o')\n",
        "    plt.title('DenseNET Accuracy evolution - Training: Cancer vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('Accuracy on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n",
        "\n",
        "plt.subplot(4, 2, 4)\n",
        "for i, h in enumerate(histories):\n",
        "    plt.plot(list(range(1, 36)), h.history['val_accuracy'], marker='o')\n",
        "    plt.title('DenseNET Accuracy evolution - Validations: Cancer vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('Accuracy on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n",
        "\n",
        "plt.subplot(4, 2, 5)\n",
        "for i, h in enumerate(histories):\n",
        "    plt.plot(list(range(1, 36)), h.history['recall'], marker='o')\n",
        "    plt.title('DenseNET Recall evolution - Training: Cancer vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('Recall on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n",
        "\n",
        "plt.subplot(4, 2, 6)\n",
        "for i, h in enumerate(histories):\n",
        "    plt.plot(list(range(1, 36)), h.history['val_recall'], marker='o')\n",
        "    plt.title('DenseNET Recall evolution - Validations: Cancer vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('Recall on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n",
        "\n",
        "plt.subplot(4, 2, 7)\n",
        "for i, h in enumerate(histories):\n",
        "    key_auc = f\"AUC_{i+1}\"\n",
        "    plt.plot(list(range(1, 36)), h.history[key_auc], marker='o')\n",
        "    plt.title('DenseNET AUC evolution - Training: Cancer vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('AUC on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])\n",
        "\n",
        "plt.subplot(4, 2, 8)\n",
        "for i, h in enumerate(histories):\n",
        "    key_auc_val = f\"val_AUC_{i+1}\"\n",
        "    plt.plot(list(range(1, 36)), h.history[key_auc_val], marker='o')\n",
        "    plt.title('DenseNET AUC evolution - Validations: Cancer vs others classes')\n",
        "    plt.xlabel('epoch number')\n",
        "    plt.ylabel('AUC on epoch')\n",
        "    plt.legend(['fold-1','fold-2', 'fold-3', 'fold-4', 'fold-5'])"
      ],
      "metadata": {
        "id": "eQX1W4WiPD0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Best results in validations for any k-fold: ')\n",
        "for i, h in enumerate(histories):\n",
        "    print(f'K-FOLD {i+1}:')\n",
        "    print(\"TRAINING RESULTS:\")\n",
        "    k = np.max(h.history[f'AUC_{i+1}'])\n",
        "    print(f'Best AUC in train: {k}')\n",
        "    k = np.max(h.history[f'accuracy'])\n",
        "    print(f'Best Accuracy in train: {k}')\n",
        "    k = np.max(h.history[f'precision'])\n",
        "    print(f'Best Precision in train: {k}')\n",
        "    k = np.max(h.history[f'recall'])\n",
        "    print(f'Best Recall in train: {k}')\n",
        "\n",
        "    print(\"\\nVALIDATION RESULTS:\")\n",
        "    k = np.max(h.history[f'val_AUC_{i+1}'])\n",
        "    print(f'Best AUC in validation: {k}')\n",
        "    k = np.max(h.history[f'val_accuracy'])\n",
        "    print(f'Best Accuracy in validation: {k}')\n",
        "    k = np.max(h.history[f'val_precision'])\n",
        "    print(f'Best Precision in validation: {k}')\n",
        "    k = np.max(h.history[f'val_recall'])\n",
        "    print(f'Best Recall in validation: {k}')\n",
        "    print()\n",
        "    print(f'{50*\"=\"}')\n",
        "    print()\n",
        "\n",
        "results = np.empty((4, 5))\n",
        "for i, h in enumerate(histories):\n",
        "    results[0][i] = np.max(h.history[f'val_AUC_{i+1}'])\n",
        "    results[1][i] = np.max(h.history['val_accuracy'])\n",
        "    results[2][i] = np.max(h.history['val_precision'])\n",
        "    results[3][i] = np.max(h.history['val_recall'])\n",
        "\n",
        "print(f\"Average best AUC: {np.mean(results[0])}\")\n",
        "print(f\"standard deviation AUC: {np.std(results[0])}\\n\")\n",
        "print(f\"Average best Accuracy: {np.mean(results[1])}\")\n",
        "print(f\"Standard Deviation Accuracy: {np.std(results[1])}\\n\")\n",
        "print(f\"Average best Precision: {np.mean(results[2])}\")\n",
        "print(f\"Standard Deviation Precision: {np.std(results[2])}\\n\")\n",
        "print(f\"Average best Recall: {np.mean(results[3])}\")\n",
        "print(f\"Standard Deviation Recall: {np.std(results[3])}\\n\")"
      ],
      "metadata": {
        "id": "FMODTgl3PF-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TESTS"
      ],
      "metadata": {
        "id": "30T9_RxuPGW0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NORMAL VS OTHERS\n"
      ],
      "metadata": {
        "id": "Do2GI06KPKyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_generator = DataGenerator(objective=[1, 0, 0, 0],\n",
        "                                       list_IDs=X_train,\n",
        "                                       labels_dir='/kaggle/input/labelsssssss/labels.csv',\n",
        "                                       dim_img=(192, 256),\n",
        "                                       batch_size=5,\n",
        "                                       sub_batch_size=400,\n",
        "                                       shuffle=True,\n",
        "                                       training=True)\n",
        "\n",
        "densenet = DenseNET()\n",
        "\n",
        "densenet.compile(loss='binary_crossentropy',\n",
        "                  optimizer=keras.optimizers.Adam(1e-7),\n",
        "                  metrics=[keras.metrics.AUC(name='AUC'),\n",
        "                           keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "                           keras.metrics.Precision(name='precision'),\n",
        "                           keras.metrics.Recall(name='recall')])\n",
        "\n",
        "\n",
        "# Train model on dataset\n",
        "densenet.load_weights('/kaggle/working/models/normal_auc1/') #start with best AUC in validations\n",
        "history = densenet.fit(training_generator, epochs=5)"
      ],
      "metadata": {
        "id": "dlS3Epm1PHqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = []\n",
        "for x in X_test:\n",
        "    x = np.load(x)\n",
        "    x = np.array(separate_slices(x))\n",
        "    pred = densenet.predict(np.array(x), verbose=0)\n",
        "    if (pred.mean() > 0.5):\n",
        "        res.append(1)\n",
        "    else:\n",
        "        res.append(0)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "kS5Lszn8PMeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_confusion = np.array([[0, 0], [0, 0]])\n",
        "\n",
        "for y_pred, y_true in zip(res, y_test):\n",
        "    if y_true != 1:\n",
        "        y_true = 0\n",
        "    else:\n",
        "        y_true = 1\n",
        "\n",
        "    matrix_confusion[y_pred][y_true] += 1\n",
        "print(matrix_confusion)\n",
        "print((matrix_confusion[0][0] + matrix_confusion[1][1])/matrix_confusion.sum())"
      ],
      "metadata": {
        "id": "2382E7noPMi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Actionable vs others"
      ],
      "metadata": {
        "id": "Sqg1db2KPSL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_generator = DataGenerator(objective=[0, 1, 0, 0],\n",
        "                                       list_IDs=X_train,\n",
        "                                       labels_dir='/kaggle/input/labelsssssss/labels.csv',\n",
        "                                       dim_img=(192, 256),\n",
        "                                       batch_size=5,\n",
        "                                       sub_batch_size=400,\n",
        "                                       shuffle=True,\n",
        "                                       training=True)\n",
        "\n",
        "densenet = DenseNET()\n",
        "\n",
        "densenet.compile(loss='binary_crossentropy',\n",
        "                  optimizer=keras.optimizers.Adam(1e-7),\n",
        "                  metrics=[keras.metrics.AUC(name='AUC'),\n",
        "                           keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "                           keras.metrics.Precision(name='precision'),\n",
        "                           keras.metrics.Recall(name='recall')])\n",
        "\n",
        "\n",
        "# Train model on dataset\n",
        "densenet.load_weights('/kaggle/working/models/actionable_auc1/') #start with best AUC in validations\n",
        "history = densenet.fit(training_generator, epochs=5)"
      ],
      "metadata": {
        "id": "NnZAHOHPPMpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = []\n",
        "for x in X_test:\n",
        "    x = np.load(x)\n",
        "    x = np.array(separate_slices(x))\n",
        "    pred = densenet.predict(np.array(x), verbose=0)\n",
        "    if (pred.mean() > 0.5):\n",
        "        res.append(1)\n",
        "    else:\n",
        "        res.append(0)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "yznQty53PUxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_confusion = np.array([[0, 0], [0, 0]])\n",
        "\n",
        "for y_pred, y_true in zip(res, y_test):\n",
        "    if y_true != 1:\n",
        "        y_true = 0\n",
        "    else:\n",
        "        y_true = 1\n",
        "\n",
        "    matrix_confusion[y_pred][y_true] += 1\n",
        "print(matrix_confusion)\n",
        "print((matrix_confusion[0][0] + matrix_confusion[1][1])/matrix_confusion.sum())"
      ],
      "metadata": {
        "id": "tVKXoes6PV4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BENIGN VS OTHERS"
      ],
      "metadata": {
        "id": "wjElo5rVPX5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_generator = DataGenerator(objective=[0, 0, 1, 0],\n",
        "                                       list_IDs=X_train,\n",
        "                                       labels_dir='/kaggle/input/labelsssssss/labels.csv',\n",
        "                                       dim_img=(192, 256),\n",
        "                                       batch_size=5,\n",
        "                                       sub_batch_size=400,\n",
        "                                       shuffle=True,\n",
        "                                       training=True)\n",
        "\n",
        "densenet = DenseNET()\n",
        "\n",
        "densenet.compile(loss='binary_crossentropy',\n",
        "                  optimizer=keras.optimizers.Adam(1e-7),\n",
        "                  metrics=[keras.metrics.AUC(name='AUC'),\n",
        "                           keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "                           keras.metrics.Precision(name='precision'),\n",
        "                           keras.metrics.Recall(name='recall')])\n",
        "\n",
        "\n",
        "# Train model on dataset\n",
        "densenet.load_weights('/kaggle/working/models/benign_auc5/') #start with best AUC in validations\n",
        "history = densenet.fit(training_generator, epochs=5)"
      ],
      "metadata": {
        "id": "g9zqg0cvPYRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = []\n",
        "for x in X_test:\n",
        "    x = np.load(x)\n",
        "    x = np.array(separate_slices(x))\n",
        "    pred = densenet.predict(np.array(x), verbose=0)\n",
        "    if (pred.mean() > 0.5):\n",
        "        res.append(1)\n",
        "    else:\n",
        "        res.append(0)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "fZEDqgXDPZZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_confusion = np.array([[0, 0], [0, 0]])\n",
        "\n",
        "for y_pred, y_true in zip(res, y_test):\n",
        "    if y_true != 2:\n",
        "        y_true = 0\n",
        "    else:\n",
        "        y_true = 1\n",
        "\n",
        "    matrix_confusion[y_pred][y_true] += 1\n",
        "print(matrix_confusion)\n",
        "print((matrix_confusion[0][0] + matrix_confusion[1][1])/matrix_confusion.sum())"
      ],
      "metadata": {
        "id": "vxK_UXmZPaie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CANCER VS OTHERS\n"
      ],
      "metadata": {
        "id": "PGZJODoNPbf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_generator = DataGenerator(objective=[0, 0, 0, 1],\n",
        "                                       list_IDs=X_train,\n",
        "                                       labels_dir='/kaggle/input/labelsssssss/labels.csv',\n",
        "                                       dim_img=(192, 256),\n",
        "                                       batch_size=5,\n",
        "                                       sub_batch_size=400,\n",
        "                                       shuffle=True,\n",
        "                                       training=True)\n",
        "\n",
        "densenet = DenseNET()\n",
        "\n",
        "densenet.compile(loss='binary_crossentropy',\n",
        "                  optimizer=keras.optimizers.Adam(1e-7),\n",
        "                  metrics=[keras.metrics.AUC(name='AUC'),\n",
        "                           keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "                           keras.metrics.Precision(name='precision'),\n",
        "                           keras.metrics.Recall(name='recall')])\n",
        "\n",
        "\n",
        "# Train model on dataset\n",
        "densenet.load_weights('/kaggle/working/models/cancer_auc3/') #start with best AUC in validations\n",
        "history = densenet.fit(training_generator, epochs=5)"
      ],
      "metadata": {
        "id": "YE06KinDPc7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = []\n",
        "for x in X_test:\n",
        "    x = np.load(x)\n",
        "    x = np.array(separate_slices(x))\n",
        "    pred = densenet.predict(np.array(x), verbose=0)\n",
        "    if (pred.mean() > 0.5):\n",
        "        res.append(1)\n",
        "    else:\n",
        "        res.append(0)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "-LP9-iOWPd9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_confusion = np.array([[0, 0], [0, 0]])\n",
        "\n",
        "for y_pred, y_true in zip(res, y_test):\n",
        "    if y_true != 3:\n",
        "        y_true = 0\n",
        "    else:\n",
        "        y_true = 1\n",
        "\n",
        "    matrix_confusion[y_pred][y_true] += 1\n",
        "print(matrix_confusion)\n",
        "print((matrix_confusion[0][0] + matrix_confusion[1][1])/matrix_confusion.sum())"
      ],
      "metadata": {
        "id": "ZmEpRFBMPe94"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}