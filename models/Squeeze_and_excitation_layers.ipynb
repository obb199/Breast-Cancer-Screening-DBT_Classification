{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "NHxB58XOhxzT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SE_ResidualUnit_bottleneck(keras.layers.Layer):\n",
        "    def __init__(self, filters, strides=1, activation='relu', **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.activation = keras.activations.get(activation)\n",
        "\n",
        "        self.SE = [keras.layers.GlobalAvgPool2D(),\n",
        "                   keras.layers.Flatten(),\n",
        "                   keras.layers.Dense(filters//4, activation='relu'),\n",
        "                   keras.layers.Dense(filters, activation='sigmoid'),\n",
        "                   keras.layers.Reshape([1,1,filters])]\n",
        "\n",
        "        self.block_layers = [keras.layers.Conv2D(filters//4, kernel_size=(1,1), strides=1, padding='same', use_bias=False),\n",
        "                             keras.layers.BatchNormalization(),\n",
        "                             self.activation,\n",
        "                             keras.layers.Conv2D(filters//4, kernel_size=(3,4), strides=strides, padding='same', use_bias=False),\n",
        "                             keras.layers.BatchNormalization(),\n",
        "                             self.activation,\n",
        "                             keras.layers.Conv2D(filters, kernel_size=(1,1), strides=1, padding='same', use_bias=False),\n",
        "                             keras.layers.BatchNormalization()]\n",
        "        \n",
        "        self.skip_layers = []\n",
        "        if strides > 1:\n",
        "            self.skip_layers = [keras.layers.Conv2D(filters, kernel_size=(1,1), strides=strides, padding='same', use_bias=False),\n",
        "                                keras.layers.BatchNormalization()]\n",
        "\n",
        "    def call(self, x):\n",
        "        inputs = tf.identity(x)\n",
        "        x1 = tf.identity(x)\n",
        "        \n",
        "        for layer in self.block_layers:\n",
        "            x1 = layer(x1)\n",
        "\n",
        "        x2 = tf.identity(x1)\n",
        "        for layer in self.SE:\n",
        "          x2 = layer(x2)\n",
        "        \n",
        "        prod_calibration = x1*x2\n",
        "        \n",
        "        for layer in self.skip_layers:\n",
        "            inputs = layer(inputs)\n",
        "        \n",
        "        \n",
        "        return self.activation(prod_calibration + inputs)"
      ],
      "metadata": {
        "id": "UzY3kzdWh6TH"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SE_ResidualUnit_default(keras.layers.Layer):\n",
        "    def __init__(self, filters, strides=1, activation='relu', **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.activation = keras.activations.get(activation)\n",
        "\n",
        "        self.SE = [keras.layers.GlobalAvgPool2D(),\n",
        "                   keras.layers.Flatten(),\n",
        "                   keras.layers.Dense(filters//4, activation='relu'),\n",
        "                   keras.layers.Dense(filters, activation='sigmoid'),\n",
        "                   keras.layers.Reshape([1,1,filters])]\n",
        "\n",
        "        self.block_layers = [keras.layers.Conv2D(filters, kernel_size=(3,4), strides=strides, padding='same', use_bias=False),\n",
        "                             keras.layers.BatchNormalization(),\n",
        "                             self.activation,\n",
        "                             keras.layers.Conv2D(filters, kernel_size=(3,4), strides=1, padding='same', use_bias=False),\n",
        "                             keras.layers.BatchNormalization()]\n",
        "        \n",
        "        self.skip_layers = []\n",
        "        if strides > 1:\n",
        "            self.skip_layers = [keras.layers.Conv2D(filters, kernel_size=(1,1), strides=strides, padding='same', use_bias=False),\n",
        "                                keras.layers.BatchNormalization()]\n",
        "\n",
        "    def call(self, x):\n",
        "        inputs = tf.identity(x)\n",
        "        x1 = tf.identity(x)\n",
        "        \n",
        "        for layer in self.block_layers:\n",
        "            x1 = layer(x1)\n",
        "\n",
        "        x2 = tf.identity(x1)\n",
        "        for layer in self.SE:\n",
        "          x2 = layer(x2)\n",
        "        \n",
        "        prod_calibration = x1*x2\n",
        "        \n",
        "        for layer in self.skip_layers:\n",
        "            inputs = layer(inputs)\n",
        "        \n",
        "        \n",
        "        return self.activation(prod_calibration + inputs)"
      ],
      "metadata": {
        "id": "9Rdx347Mkmey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SE_InceptionModule(keras.layers.Layer):\n",
        "    def __init__(self, filters, activation='relu', **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        SE_filters = filters[0] + filters[2] + filters[4] + filters[5]\n",
        "        self.SE = [keras.layers.GlobalAvgPool2D(),\n",
        "                   keras.layers.Flatten(),\n",
        "                   keras.layers.Dense(SE_filters//4, activation='relu'),\n",
        "                   keras.layers.Dense(SE_filters, activation='sigmoid'),\n",
        "                   keras.layers.Reshape([1, 1, SE_filters])]\n",
        "\n",
        "        self.activation = keras.activations.get('relu')\n",
        "        \n",
        "        self.conv_a    = keras.layers.Conv2D(filters[0], kernel_size=(1,1), padding='same', use_bias='false', strides=1)\n",
        "        self.bn_a      = keras.layers.BatchNormalization()\n",
        "        \n",
        "        self.conv_b1   = keras.layers.Conv2D(filters[1], kernel_size=(1, 1), padding='same', use_bias='false', strides=1)\n",
        "        self.conv_b2   = keras.layers.Conv2D(filters[2], kernel_size=(3, 4), padding='same', use_bias='false', strides=1)\n",
        "        self.bn_b      = keras.layers.BatchNormalization()\n",
        "        \n",
        "        self.conv_c1   = keras.layers.Conv2D(filters[3], kernel_size=(1, 1), padding='same', use_bias='false', strides=1)\n",
        "        self.conv_c2   = keras.layers.Conv2D(filters[4], kernel_size=(5, 6), padding='same', use_bias='false', strides=1)\n",
        "        self.bn_c      = keras.layers.BatchNormalization()\n",
        "        \n",
        "        self.maxpool_d = keras.layers.MaxPooling2D(pool_size=(3, 4), padding='same', strides=1)\n",
        "        self.conv_d    = keras.layers.Conv2D(filters[5], kernel_size=(1, 1), padding='same', use_bias='false', strides=1)\n",
        "        self.bn_d      = keras.layers.BatchNormalization()\n",
        "        \n",
        "    def call(self, x):\n",
        "        out1 = self.conv_a(x)\n",
        "        out1 = self.bn_a(out1)\n",
        "        out1 = self.activation(out1)\n",
        "        \n",
        "        out2 = self.conv_b1(x)\n",
        "        out2 = self.conv_b2(out2)\n",
        "        out2 = self.bn_b(out2)\n",
        "        out2 = self.activation(out2)\n",
        "        \n",
        "        out3 = self.conv_c1(x)\n",
        "        out3 = self.conv_c2(out3)\n",
        "        out3 = self.bn_c(out3)\n",
        "        out3 = self.activation(out3)\n",
        "        \n",
        "        out4 = self.maxpool_d(x)\n",
        "        out4 = self.conv_d(out4)\n",
        "        out4 = self.bn_d(out4)\n",
        "        out4 = self.activation(out4)\n",
        "\n",
        "        y = tf.concat([out1, out2, out3, out4], axis=3)\n",
        "        y_calibration = tf.identity(y)\n",
        "\n",
        "        for layer in self.SE:\n",
        "          y_calibration = layer(y_calibration)\n",
        "        \n",
        "        return y_calibration * y"
      ],
      "metadata": {
        "id": "6BF6_4AblDHA"
      },
      "execution_count": 37,
      "outputs": []
    }
  ]
}